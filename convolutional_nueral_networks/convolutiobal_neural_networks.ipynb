{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ecdc749-3f88-4970-a0d6-245189f5d5e8",
   "metadata": {},
   "source": [
    "# Basics of Convolutional Neural Networks\n",
    "# Project Description\n",
    "In this notebook I will go over some basics for convoluitinal neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315ea210-8cca-4338-8fff-24a5f2e0412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca380d-129d-40df-b497-d6af6e0ece5e",
   "metadata": {},
   "source": [
    "# How CNN's Work\n",
    "First lets go over what a convolution is. I will go over very basics in this notebook but if you want to read more I have a notebook on my github show casing what convolutions are and do. The notebook can be found [here](https://github.com/GaelGil/notebooks/blob/master/convolutions/convolutuionExample.ipynb). A convolution is when\n",
    "\n",
    "So what our model is doing is passing a kernel over the image to get another image. This is what a convolution is. \n",
    "\n",
    "Feature extraction. During convolutions the filter is picking up on things from the image. For example lets say we have a photo of a the letter `X`. The filter would pick the diagonal lines on the image. During the convolution the filter would pick that up and pass it forward. This is feature extraction. The convolutions are getting us our features for us. This means that the convolutions are telling us what in this photo is significant. If we had an image of the letter `O`. The kernels would pick up on the curves of the letter and pass those forward. This will help us learn what is important in the `O`. Therefore getting us features which are important for our model to make a prediction. Features are data. For example in mnist our features are all the pixels in the image. In the .... dataset the is our features. So what convolutions do is get those for us. \n",
    "\n",
    "Once we have these features what do we do with them? Once we have the features what we do is pass them through a fully connected neural network. We feed the features forward to get an output. To learn more about fully connected networks check out my notebook on [github](https://github.com/GaelGil/notebooks/blob/master/back-propagation/back_propagation.ipynb). It goes over feeding forward and back propagation. That is how we go from image to a prediction. One way to think about it is using mnist. \n",
    "- What is convolution\n",
    "- What is a filter/kernel\n",
    "- Max/Min pooling\n",
    "- How do we get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3932a56-5e1c-4e63-abef-de9905b083eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for our gpu\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7e151-3292-45fc-a6e3-96269d4feae3",
   "metadata": {},
   "source": [
    "# Loading and Formating the Data\n",
    "- create a dataframe\n",
    "- split into train test and validate\n",
    "- format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7141281-b3ad-480a-bc2c-4594820435aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = './data/PetImages/train'\n",
    "DATA_EVAL_PATH = './data/PetImages/eval'\n",
    "DATA_TEST_PATH = './data/PetImages/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9ec7fd-fb67-49f1-b124-5c47be143b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(len(data)*.7)\n",
    "# val_size = int(len(data)*.2)\n",
    "# test_size = int(len(data)*.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a473c-ed1b-4523-85d4-3e59fed57ec9",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d896251-043f-4a3c-8678-7b190c8f5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.fc1 = nn.Linear(input, output)\n",
    "        self.fc2 = nn.Linear(input, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ec8b2-b3ca-4f05-b4af-d6c1366237e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs, lr):\n",
    "    \"\"\"\n",
    "    Function to train our neural network.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : class\n",
    "        The model we are trying to train.\n",
    "    data : \n",
    "        The data for training.\n",
    "    epochs : int\n",
    "        How many iterations of training we are going to do.\n",
    "        \n",
    "    lr : float\n",
    "        The learning rate of our model\n",
    "    \"\"\"\n",
    "    net = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6d529-df2a-43d2-b9f7-80d6bc22117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model=Net, PATH, epochs=20,  lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6594b-eb99-4679-b146-20843d8eabee",
   "metadata": {},
   "source": [
    "# Analyzing Performence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41eb6e-938b-4165-9f82-b73d85e9d1da",
   "metadata": {},
   "source": [
    "# What Does the CNN See?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
