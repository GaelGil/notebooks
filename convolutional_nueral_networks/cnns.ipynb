{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ecdc749-3f88-4970-a0d6-245189f5d5e8",
   "metadata": {},
   "source": [
    "# Basics of Convolutional Neural Networks\n",
    "# Project Description\n",
    "In this notebook I will go over some of the basics of convolutional neural networks. This notebook will cover what a convolution is, kernels/filters, max/min pooling etc. At the end of explaining the basics I will build a convolutional neural network using pytorch to classify some images. I am doing this project because I wanted to learn how to use pytorch while also implementing and learning about convolutional neural networks. Some knowledge of neural networks would be helpful for this project as well as some python knowledge. If you want to learn more about neural networks I have a notebook where I explain the math and implement one from scrath [here](https://github.com/GaelGil/notebooks/blob/master/convolutions/convolutuionExample.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe3e48-eeea-4046-ba42-ad2ac6fb5fb6",
   "metadata": {},
   "source": [
    "# CNN Architecture\n",
    "Just like in regular feed forward neural networks, in convolutional networks we also have layers. We have the convolutional layer, pooling layer, activation layer and the feed forward part of our network. This is a photo of what it looks like. We will go over each part later in the notebook.\n",
    "## What is a convolution?\n",
    "Lets start of with what a convolution is.  A convolution in math is when we combine two functions to get a third one. The convolution of \n",
    "\n",
    "example\n",
    "is given by \n",
    "formula\n",
    "\n",
    "In convolutional neural networks we have an image which we can represent with a matrix and a kernel/filter which is also a matrix. So what we will do is pass a kernel over the image to get another image. This is our convolution. I will demonstrate this more later. \n",
    "\n",
    "What convolutions do is help us extract features from an image. These features will help us classify our image. For example let's say we have a black and white image of the letter X. The kernel would pick up on the diagonal lines of the image and move that forward in the network. If we had an image of the letter O. The kernels would pick up on the curves of the letter and pass those features forward.\n",
    "\n",
    "The with each iteration the kernels will pick up on features that will help us make a prediction. Essentially the convolutons are telling us what in this image is significant. This is feature extraction. Now the important thing is that we have to learn the correct value for the weights in the kernel so that we can get those important features. \n",
    "\n",
    "## What is a kernel?\n",
    "**A kernel is a matrix** that we use in a convolution to get another image. It is also called a filter but in this notebook I will refer to it as a kernel. If you have ever used a filter on social media to make a photo black and white or make it look like a drawing. It most likely uses a convolution to achieve that. This is done by performing a convolution on the image with the kernel.\n",
    "Here is an example of a kernel:\n",
    "\n",
    "$$ kernel = \\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "0 & 3\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463c21d-2d5a-4eaf-9c99-59312838bf1a",
   "metadata": {},
   "source": [
    "Here is an example of an image, it vaguely looks like a 7. In this case we have one channel. If we had a colored image we would have 3 channels. One for red, green and blue, each its own matrix. Becuase we have one channel (matrix) our image is a gray scale image. Each pixel would be a value between 0 and 1 where 0 is black and 1 is white. For simplicity I made them all 1 and 0.\n",
    "\n",
    "$$ image = \\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 1 & 1 & 1 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Lets perform the convolution of our image and our kernel.\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "0 & 3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "0 & 3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$ \n",
    "\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "0 & 3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Here is the convolution of the image and kernel(padding=0).\n",
    "\n",
    "$$ image = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Lets demonstrate this in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67b306-87eb-4bc4-aaf7-c5755e281bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be268f06-f15b-46c3-8381-9f4f31ebbc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.\n",
    "image = np."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1aaa8e-4f7e-471a-a863-abc771fccf2a",
   "metadata": {},
   "source": [
    "Since we went over the basics of convolutions lets now go over how convolutional layers work on a colored image. As mentioned if we have a colored image we will have 3 channels (3 matrices) for red green and blue. This will look like this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2754d6-d4dd-43bc-be4b-69b266b17aba",
   "metadata": {},
   "source": [
    "$$\n",
    "r = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "g = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "b = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352f7d0-62fd-48f4-9ee4-7f63002b0ea9",
   "metadata": {},
   "source": [
    "This is our image we have nxnx3 image. The three represents the color channels. Each matrix its pixels contain the intensity for each color red green and blue. This is our input so our next step would be to pass it through the convolutional layer. As mentioned earlier in our models we will have convolutional layers in which we take a number of nxn kernels and perform a convolution on our image. Each kernel can be thought of as a node in a fully connected network. Lets take an example with the model we built in pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ce4fe-5f0e-4d45-83f9-79ddb0fffb6f",
   "metadata": {},
   "source": [
    "Our images are colered images of size nxn. So we have nxnx3. Our first convolutional layers contain 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec0e71-0161-41fc-8f80-8a625d4ea66d",
   "metadata": {},
   "source": [
    "## Max/Min Pooling\n",
    "Max/Min Pooling is the process in which we go through our image picking either the smallest or largest value in a nxn grid covering the image. Below is an example of an image in which we have performed max pooling with a 2x2 grid with a stride of 1. Stride is how much we slide the grid by.\n",
    "\n",
    "$$ image = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$ maxPoolImage = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## How do we get a prediction from this?\n",
    "Once we have the features that have been extracted by our convolutional layers what we do is pass them through a fully connected neural network. Where our output layer will be the layer that predicts what class something belongs to. For example when using a neural network to solve MNIST you flatten the image to be 28x28=784. That would go into the input layer. Then we pass the image through the network to get a prediction. Our output layer is of course made of 10 neurons each for a number 0-9. The same is done for CNN. Once the convolutions are done all the features we have are flattened and passed to a fully connected neural network. We can actually think of the MNIST dataset as images of hand written digits which have already had convolutions performed on them. We are now just given the features to classify the digits. To learn more about fully connected networks check out my notebook on [github](https://github.com/GaelGil/notebooks/blob/master/back-propagation/back_propagation.ipynb). It goes over feeding forward and back propagation using MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7e151-3292-45fc-a6e3-96269d4feae3",
   "metadata": {},
   "source": [
    "# Loading and Formating the Data\n",
    "The data I will be using is an image dataset of dogs and cats that I got from kaggle. The image consists of two folders one for dogs and one for cats. Each folder has 12499 photos for each class. I decided to use this dataset because I thought it would be cool to create a model where I can take a photo of my dog and it could classify it correctly.\n",
    "Loading the data in is pretty simple. We simply use the ImageFolder function from pytorch and it loads it for us. One thing to mention is that as we open it we want to do some transformations to the images. For example the transformations that I made to the dataset is resizing to 255x255, made them to pytorch tensors, and normalized it. Normalizing makes all pixels the values in the image to be within a range. Instead of being in a range of 0-255 it is from 0-1. Normalizing the data helps with training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea7190-f956-4a7e-90dc-1412c055924f",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "Now that we have covered some basics we can go into building the model. The model will have 3 convolutional layers. After each convolution there will be a linearization and a max pool layer of stride 2. The first convolutional layer will have three input channels because we are using rgb images. The output channels will be 6 and we will have a kernel size 5x5 (by default padding = 0 and stride=1). Our second convolutional layer will have sixt input channels because we previously had six output channels and 16 output channels (same kernel size for all convolutional layers). Lastly our final convolutional layer will have 16 input channels and 32 output channels. All layers will be followed by a relu and max pooling (2x2, stride=1).\n",
    "Now we get into the fully connected layers. We flatten all our convolutional layers and our input layer will be 32*28*28. I got this number by passing a sample through the network and printing the shape of the final convolutional layer. We will have 120 output features. Lastly our final output layer will have 120 input features and 1 output feature. This will be responsible for our classification/prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccf3ef-9d6e-4b0f-a79d-12cc97a9053a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TODO:\n",
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ab850-cb97-4981-a0e9-2999e843595c",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "# Analyzing Performence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41eb6e-938b-4165-9f82-b73d85e9d1da",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "# What Does the CNN See?\n",
    "- Show images of what the model is doing to the images as it passses through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7aae47-7cd4-427b-9ee9-b1b577d12e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
