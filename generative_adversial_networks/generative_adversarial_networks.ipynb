{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c684f6a0-da31-4908-8add-7339fc43a923",
   "metadata": {},
   "source": [
    "# Introduction/Project Overview:\n",
    "\n",
    "In this notebook I will go over generative adversarial networks also known as GAN's. I will briefly explain their history, model architechture and the math behind them. This notebook will cover convolutional GANS and the proggresive growing of GANS. I have used these videos here as guides and inspiration for this project. [videos](https://www.youtube.com/watch?v=OXWvrRLzEaU&list=PLhhyoLH6IjfwIp8bZnzX8QR30TRcHO8Va) . This notebook will mainly be markdown but the code will be in the src folder in this repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d943895-c95f-4235-9f31-2f63dc0f2168",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks \n",
    "A generative adversarial network (aka GAN) is a model that generates new data that is similar to its training data. As the name implies in this neural network architechture where there are two networks competing with each other. We have the `generator` which is responsible for generating data similar to the training data and the `discriminator` whos goal is to goal is to correctly classify real data. The idea of GANs is to train the generator to be generate new examples of data so similar to its training examples that the discrimiantor classifies them as real data. Initially we start with random noise (a matrix with random pixel values) and through each iteration the generator learns to generate real looking data.\n",
    "\n",
    "Here is a diagram of what the typical gan looks like ...\n",
    "\n",
    "The use cases of GANS are generating new data, merging images, generating high resolution images from low ones, and generating audio. But how exactly do we train these two neural networks.\n",
    "\n",
    "Before we get into any math, lets think about what our goal is. Our goal is to train a neural network to correctly classify real data (generator) and train another network to generate data (generator) that discriminator belives to be real.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53585a",
   "metadata": {},
   "source": [
    "With this statement comes this formula for the loss function.\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{loss} = \\frac{1}{n} \\sum_{i=1}^{n} (\\log(D(x_i)) + \\log(1-D(G(z_i))))\n",
    "$$\n",
    "$$\n",
    "$$\n",
    "Lets break it down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40425e61-9db9-4a41-8e27-cd8b70722aa2",
   "metadata": {},
   "source": [
    "## Deep Convolutional Gans\n",
    "With deep convolutional gans we use the power of convolutions to help us generate images. As with classification convolutions are very powerful at learning important features in images. We will use convolutions to help us learn features to generate some higher quality data and also add some in the discriminator to improve its classification ability.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "##### Discriminator\n",
    "Our discriminator contains five convolutional layers. Our first convolution is followed by a LeakyReLU. Next we ahve three convolutional layers that are each followed by batchnorm and leakyrelu. After the three convolutional layers we have just one more convolutional layer. Which is followed by a single node of sigmoid function. This will output a value between 0 and 1 for our classification.\n",
    "\n",
    "##### Discriminator\n",
    "Our generator is essentially the discriminator in reversed. So we will start \n",
    "\n",
    "\n",
    "\n",
    "### Training\n",
    "With GANS it is important to note that we use a different error fucntion that we might be used to. Lets go over it\n",
    "\n",
    "\n",
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f1730a-f7bb-4022-adad-aae5f9ead1f4",
   "metadata": {},
   "source": [
    "## Progressive Growing of Gans (ProGan)\n",
    "Progressive growing of gans is the next upgrade in generative adversarial networks. The idea is to train the generator and discriminator to generate and classifiy a small nxn samples. For example our discriminator will begin with only generating 4x4 images and therfore our discriminator will also do the same. Through time we move from 4x4 to 16x16 and 32x32n and so on. \n",
    "\n",
    "### Architecture\n",
    "\n",
    "### Training\n",
    "\n",
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57929283-71a8-4d5a-9698-24d373c7e443",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
