{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e51b806-7f36-4530-b0d7-23acff5ee99f",
   "metadata": {},
   "source": [
    "# Introduction/Project Overview:\n",
    "\n",
    "In this notebook, I will go over the World Health Organization Life Expectancy dataset. This dataset can be found on [kaggle](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who). We are given data on a country, population, health issues, life expectancy, etc. Our goal would be to create a model that can accurately determine the life expectency given a some characteristics on a population. Throughout this notebook I will visualize the data, explain some data preprocessing techniques, construct and evaluate models and analyze the results.\n",
    "\n",
    "### Data Exploration & Preprocessing:\n",
    "I will go over the dataset, analyzing its various features, checking for missing values, and gaining insights into the distribution of variables. Prior to building the models, I will preprocess the data by handling missing values, encoding categorical variables, and scaling numerical features to ensure good model performance.\n",
    "\n",
    "### Model Building & Evaluation:\n",
    "In this notebook I will try implement a couple of models to try and see which ones are more accurate at predicting life expectancy. This is a supervised learning task since we are given the life expectancy of these population. Additionally this is a regression tasks because we are trying to predict a numerical value rather then put something into a category. For this notebook the models I chose is multiple linear regression, polynomial regression and a neural network. Lastly I will interpret the results of each model. \n",
    "\n",
    "\n",
    "### Conclusion:\n",
    "Finally, I will be discussing potential areas for model improvement, what stood out to me and what were some challanges.. The conclusion serves more as a reflection for me on my time working on this notebook. This will serve as a good test for me to keep learning and testing my skills. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b248c12e-b04c-4149-9126-4ff4d9abfa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e8cac-a333-4f75-be18-627b0cb61ad8",
   "metadata": {},
   "source": [
    "## Data Exploration & Preprocessing:\n",
    "As mentioned earlier I got the dataset from kaggle. The link to that can be found above. The download came with two csv files. One for the training set and one for the test set. Since I have it locally on my computer I can eassily access the data as shown below. Some of the first steps we will do before creating a model is to see what our data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048d651-d8b9-4487-9cc3-a19eb210c8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
