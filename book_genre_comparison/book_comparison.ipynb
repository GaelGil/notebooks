{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5329f1c-a112-4676-b7d6-d7da89d69875",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "In this project I am going to see if I can visualize graphically the difference between two different types of book genres. The two book genres I am choosing to compare are cook books and gothic/horror. Before I do that tho I will start with a smaller example. First I will try to visualize positive and negative words. The way in which I will do this is by embedding some word data. This means I will turn some word `positive_word` into a vector (`[34 , 423, 5, ....  6456 , 343]`). I will get the word embeddings by using the BERT model. Once I have the embeddings I will use dimensionality reduction algorithms (PCA, TSNE) to get them down to a vector of two components. Lastly once I have done this I will then use the book data to do the same. This notebook will not go too much into the techincal aspects of BERT, PCA, TSNE. I am simply using tools to visualize text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b0c16-d042-46b3-a99b-ae98fc2cd282",
   "metadata": {},
   "source": [
    "# The Data\n",
    "First lets take a look at our data. As I mentioned first I will be using a small dataset that I created. The data can be found in the folder `./data/csv/words.csv`. It consists of two columns (word, label). Here are two examples `word=love,label=positive, word=hate,label=negative`. I will put each word through the bert model to get some embeddings. Then I will use a dimensionalty reduction algorithm to plot each word. \n",
    "Later on I will be using book data. This data has two columns. I got this data from [here](https://www.gutenberg.org/). First we will import some useful tools that will help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4912f135-7f92-4522-8e44-72ba2ab74374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b6f46-a0b2-4156-8099-ab05da70675e",
   "metadata": {},
   "source": [
    "# First Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22075b8-aeb9-4923-98a4-21a77e1ded4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/csv/words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f163e-e231-459a-8751-4bda01508674",
   "metadata": {},
   "source": [
    "Here is our data. As we can see it is really simple. We have a word and its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959e5989-2766-46d3-a75f-dda344bcc678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terrific</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admired</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jolly</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brave</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     label\n",
       "0      love  positive\n",
       "1  terrific  positive\n",
       "2   admired  positive\n",
       "3     jolly  positive\n",
       "4     brave  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4068b662-cb69-4691-b0ac-3a70d148fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368c8384-2a91-494b-a416-0190e2a3005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize every word in the dataframe\n",
    "encoded_data = [tokenizer(i, return_tensors='pt') for i in data.word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc138070-ef87-4b3a-95b0-cb587116d081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2293,  102]]), 'token_type_ids': tensor([[0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our words have been encoded into a list of ids that look like this: tensor([[ 101, 3866,  102]]). \n",
    "# 101 and 102 are for start and stop. 3866 is the id of our actual word embedding and its what we actually\n",
    "# need. We will extract this later.\n",
    "encoded_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af9f59d6-f391-4166-897a-e0f758547c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings from our encoded data\n",
    "word_embeddings = [model(**i) for i in encoded_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf004c6-f9ef-4716-a57c-479106e85665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings[0].last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc2ccff-9da3-4f1c-ba8b-d2c459fd306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last hidden state for each of the embeddings\n",
    "embeddings = [i.last_hidden_state for i in word_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffdad094-4b12-49e4-9cc9-2388812b5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual word embeddings. \n",
    "embeddings = [i[0][1] for i in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cce1c06-9584-44dc-9bd6-b46bb2dddd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn tensor to numpy array\n",
    "embeddings = [i.detach().numpy() for i in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c886c5-b204-45a6-a3f3-ac42db24801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the embeddings to our dataframe\n",
    "data['word_embeddings'] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f38184-7fff-4a5b-8667-b6f261e06d46",
   "metadata": {},
   "source": [
    "We now have all the embeddings for our words. We can see this in the dataframe below in the column `word_embeddings`. Now that we have our embeddings we will reduce the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20381e6-76a2-4d9f-9dfa-69733968cb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>word_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.3864911, 0.36188018, 0.23423323, -0.3957976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terrific</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.33330113, -0.20869666, -0.16522153, -0.0631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admired</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.25650173, 0.022439439, 0.25480777, -0.0880...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jolly</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.22022377, -0.20243204, 0.10135944, -0.3264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brave</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.08306653, -0.118995346, -0.46022722, -0.43...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     label                                    word_embeddings\n",
       "0      love  positive  [0.3864911, 0.36188018, 0.23423323, -0.3957976...\n",
       "1  terrific  positive  [0.33330113, -0.20869666, -0.16522153, -0.0631...\n",
       "2   admired  positive  [-0.25650173, 0.022439439, 0.25480777, -0.0880...\n",
       "3     jolly  positive  [-0.22022377, -0.20243204, 0.10135944, -0.3264...\n",
       "4     brave  positive  [-0.08306653, -0.118995346, -0.46022722, -0.43..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edeea62-bf47-4eaf-86c1-48f22308198c",
   "metadata": {},
   "source": [
    "# Visualizing\n",
    "A issue with our data is that it is very high dimensional. As we can see below the shape for one example is very big. We can't just graph this so we are going to be using a some dimensionality reduction algorithms. First we are going to use PCA (prinicpal component analysis) and TSNE (T-distributed Stochastic Neighbourhood Embedding). I will not go into how these algorthims work here but you can read about them here [TSNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis#:~:text=Principal%20component%20analysis%20(PCA)%20is,components%20and%20ignoring%20the%20rest.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b2ffc3-067b-4bc5-94c1-da2bd7ddae67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.word_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "049c4eba-1a26-4bdb-a754-9400e4b44c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(list(data.word_embeddings))\n",
    "principal_df = pd.DataFrame(data = principal_components, columns=['pc_one', 'pc_two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9172a977-1c8d-4e5a-8772-ec08457363eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc_one</th>\n",
       "      <th>pc_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.714281</td>\n",
       "      <td>0.511747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.681739</td>\n",
       "      <td>-3.310147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.780258</td>\n",
       "      <td>0.753338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.881720</td>\n",
       "      <td>-0.769071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.737801</td>\n",
       "      <td>0.931425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pc_one    pc_two\n",
       "0  1.714281  0.511747\n",
       "1 -0.681739 -3.310147\n",
       "2 -1.780258  0.753338\n",
       "3 -3.881720 -0.769071\n",
       "4 -2.737801  0.931425"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our data reduced to two components by pca\n",
    "principal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28101e0a-6f77-4665-b66e-5f3e3665f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our reduced data to our main dataframe\n",
    "data = pd.concat([data, principal_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f3918c1-9481-4fc5-83d9-89c60efca0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>word_embeddings</th>\n",
       "      <th>pc_one</th>\n",
       "      <th>pc_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.3864911, 0.36188018, 0.23423323, -0.3957976...</td>\n",
       "      <td>1.714281</td>\n",
       "      <td>0.511747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terrific</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.33330113, -0.20869666, -0.16522153, -0.0631...</td>\n",
       "      <td>-0.681739</td>\n",
       "      <td>-3.310147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admired</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.25650173, 0.022439439, 0.25480777, -0.0880...</td>\n",
       "      <td>-1.780258</td>\n",
       "      <td>0.753338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jolly</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.22022377, -0.20243204, 0.10135944, -0.3264...</td>\n",
       "      <td>-3.881720</td>\n",
       "      <td>-0.769071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brave</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.08306653, -0.118995346, -0.46022722, -0.43...</td>\n",
       "      <td>-2.737801</td>\n",
       "      <td>0.931425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     label                                    word_embeddings  \\\n",
       "0      love  positive  [0.3864911, 0.36188018, 0.23423323, -0.3957976...   \n",
       "1  terrific  positive  [0.33330113, -0.20869666, -0.16522153, -0.0631...   \n",
       "2   admired  positive  [-0.25650173, 0.022439439, 0.25480777, -0.0880...   \n",
       "3     jolly  positive  [-0.22022377, -0.20243204, 0.10135944, -0.3264...   \n",
       "4     brave  positive  [-0.08306653, -0.118995346, -0.46022722, -0.43...   \n",
       "\n",
       "     pc_one    pc_two  \n",
       "0  1.714281  0.511747  \n",
       "1 -0.681739 -3.310147  \n",
       "2 -1.780258  0.753338  \n",
       "3 -3.881720 -0.769071  \n",
       "4 -2.737801  0.931425  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e0ccaee-3e05-439e-bb35-6f87aced5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the word embeddings by label (positive/negative)\n",
    "positive = data.query('label.str.contains(\"positive\")', engine='python')\n",
    "negative = data.query('label.str.contains(\"negative\")', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367fe23-43f8-4a11-a173-914b31a43398",
   "metadata": {},
   "source": [
    "<!-- Below we is a graph of our words graphed. We can see that the positive words are on the upper left of the chart and the negative words are in the middle to the right of the positive words. We can also see that they slightly overlap in the middle. We can also see that there are words that -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8734b2-e150-4794-a342-7cfe8958ca26",
   "metadata": {},
   "source": [
    "Below I have graphed our data in its reduced form by pca. As we can see there is some noticeable difference but not much. We can see that there are more negative words in the upper right of the graph. And generally most positive words are in the bottom left. One of the reasons why this did not work as we expected is because pca is meant for linear data which our data is not. Now we are going to use TSNE to see if we can get a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7be7cb24-0f1f-459e-9002-0c20c9746fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAocklEQVR4nO3deXxU9b3/8deHRSGgYhG9KpIgymYSFiOiCG5oqaVSfIhi44LWUq1e7a1LXar1/lparf6QLi7lukvEUrTVXlurRS3Q4hLcBakLYRHUiEBZFcjn/nFOwmSYJJNlcs5k3s/HYx6ZObOcz5wk38/5Luf7NXdHRERyT7uoAxARkWgoAYiI5CglABGRHKUEICKSo5QARERylBKAiEiOUgKQFmVmN5nZjFbe5yQzm9+a+6yLmb1gZhe2wn6OM7OVLfh5bmaH1PFcreNrZhvN7OCW2rdERwlAMLMKM9sS/mN/bGYPmFnXqONqCWb2VzP7YcLjA8PCLtW2/8hwLDeZ2bbwOFff1mVyn5ng7l3d/cOo45DmUwKQat9w967AYGAIcG204bSYucCohMejgHdTbHvP3T9O90Mt0JT/n9+FBWj1rVsTPkOkRSgBSC1hIfhXgkQAgJkNN7N/mtk6M3vDzI5LeK63mf3dzDaY2bPAPgnP7dJMEdY2Rof325vZdWb2Qfj+hWZ2UPhcfzN71sw+N7MlZnZGwmd0N7MnzezfZvYy0KeerzQXGJFQWI8EpgElSdvmhp99tJm9Ymbrw59HJ+z3BTObYmb/ADYDB5vZSWb2bvj63wDW8FFOLayFfM/M3guPx0/MrE947P9tZrPMbLek91xnZp+Fx7U0YfvuZnabmS03s0/M7G4z65zw/FVmttrMVpnZBUmfWe/xTWwuCmuLd5jZU2HML5lZn4TXnhz+/tab2Z3h38qF4XOHhI/Xh9/hd009dtI0SgBSi5n1BL4GvB8+PhB4Cvgp8BXgSuAxM+sRvuURYCFBwf8T4LxG7O4HwFnAKcCewAXAZjPrAjwbfva+wETgTjMbGL7vDmArsH/4nguo28vA7sCg8PGo8LPfT9o218y+En7XXwHdganAU2bWPeHzzgEmA3sA64HHgR+F3/8DYEQjvn8qXwUOB4YDVwPTgbOBg4BCguNV7T/C/R5IcNynm1m/8Lmbgb4EifyQ8DU3ApjZGILf40nAocDopBgac3wh+P38N7A3wXGdEu5nH2A2QW2yO7AEODrhfT8Bngnf1xP4dQP7kZbm7rrl+A2oADYCGwAH5gDdwud+CDyc9Pq/EhQ4vYDtQJeE5x4BZoT3jwNWptjX6PD+EmBcinjOBOYlbfst8GOgPbAN6J/w3M+A+fV8vxeAywkS2Ipw280J26qAfILC/eWk9y4AJiV8zv9LeO5c4MWExwasBC6sI46bgC+BdQm35xOed2BEwuOFwA8THv9/YFrCsU0+9rOAG8I4NgF9Ep47Clga3r8PuDnhub7hvg9J5/hWvza8/wBwT8JzpwDvJhyfBUnHZ0X18QEeIkhwPaP+H8jVm2oAUu2b7r4HQcHSn51NOfnAhLD5Z13YaXkMwdnhAcBad9+U8DnLGrHPgwjOmpPlA0cm7bOU4Iy3B9CBoCBJd5/V/QAjgX+E2+YnbFvh7svC75P8WcsIzp6rJe73gMTHHpRqic+nMsvduyXcjk96/pOE+1tSPE7snE917A8gOEZ5wMKE4/d0uH2XuKn9nZtyfBP7TjYnxJjq+CQ2CV5NkBReNrN3kpuiJPOUAKQWd/87wVndbeGmFQQ1gMRCq4u73wysBvYOm2yq9Uq4v4mgIAKCNn92FkLVn52q/X4F8PekfXZ194uBSoIz34Pq2GcqcwkK+lHAvHDbPwiaa0aFzwOsIkg+iXoBHyU8Tpw+d3ViHGZmSXFlWqpjvwr4jCBZHJZw/PbyoJMfkuKm9vFryvGty2qCph2g5vjUPHb3j939O+5+APBdgma+lENRJTOUACSVacBJZjYImAF8w8y+Gnbadgo7d3uGZ83lwH+b2W5mdgzwjYTP+RfQycy+bmYdCdrKd094/h7gJ2Z2qAWKw/b2/wX6mtk5ZtYxvB1hZgPcfQdBu/tNZpYX9gs01O+wAOhG0JY+D8Dd1xIUdmezMwH8Odzvt8ysg5mdCQwM40nlKeAwMzvNzDoAlxHUUlpT9bEfCYwFfu/uVcD/ALeb2b5QM9T1q+F7ZgGTzGygmeURNK0B0MTjW5engCIz+2Z4fC4h4fiY2YSwzwlgLUFyrWrivqQJlABkF+5eSdA+e6O7rwDGAdcRFJgrgKvY+bfzLeBI4HOCguShhM9ZD3yPoKD/iKBGkNgEMJWgMHoG+DdwL9DZ3TcAJxN0Lq4iaGK4hZ3J41KCZoaPCWor9zfwfTYRtKfvBryd8NQ8gk7mueHr1hAUolcAawiaKMa6+2d1fO5nwASC/oQ1BB2q/0j12gRnWu3rADZWF9JN8DFBwbkKKAMucvd3w+d+SNAh+6KZ/Rv4G9AvjPsvBEn+ufA1zyV9bqOOb10Sjs8vCI7PQIIThi/ClxwBvGRmG4Engctd1xe0Kgua5UREMsuCYbcrgVJ3fz7qeEQ1ABHJoLDpsJuZ7U5QizTgxYjDkpASgIhk0lEEI70+I+gf+qa7b4k2JKmmJiARkRylGoCISI7qEHUAjbHPPvt4QUFB1GGIiGSVhQsXfubuPZK3Z1UCKCgooLy8POowRESyipmlvJpbTUAiIjlKCUBEJEcpAYiI5Kis6gMQkczatm0bK1euZOvWrVGHIk3QqVMnevbsSceOHdN6vRKAiNRYuXIle+yxBwUFBQSTd0q2cHfWrFnDypUr6d27d1rvyXgTkJndZ2afmtnbCdu+YsFyf++FP/fOdBwikSorg4ICaNcu+FlWFnVEKW3dupXu3bur8M9CZkb37t0bVXtrjT6AB4AxSduuAea4+6EEq09d0wpxiESjrAwmT4Zly8A9+Dl5cmyTgAr/7NXY313GE4C7zyWYKjjROODB8P6DwDczHYdIZK6/HjZvrr1t8+Zgu0iEohoFtJ+7rw7vfwzsV9cLzWyymZWbWXllZWXrRCfSkpYvb9x2aba7776bhx4KlqZ44IEHWLVqVc1zF154IYsWLYoqtHpVVFRQWFjYavuLvBPY3d3M6pyRzt2nEywcTUlJiWauk+zTq1fQ7JNqu2TERRddVHP/gQceoLCwkAMOOACAe+65J6qwdrF9+3Y6dIiuGI6qBvCJme0PEP78NKI4RDJvyhTIy6u9LS8v2J7lWrpvu6Kigv79+1NaWsqAAQM4/fTT2Rw2n82ZM4chQ4ZQVFTEBRdcwBdfBAuLXXPNNQwcOJDi4mKuvPJKAG666SZuu+02Zs+eTXl5OaWlpQwePJgtW7Zw3HHHUV5ezt13381VV11Vs+8HHniASy+9FIAZM2YwbNgwBg8ezHe/+1127NhRK85XXnmF0047DYAnnniCzp078+WXX7J161YOPvhgAF5//XWGDx9OcXEx48ePZ+3atQAcd9xxfP/736ekpIRf/vKXLFy4kEGDBjFo0CDuuOOOmn288847NTEUFxfz3nvvNe/gpuLuGb8BBcDbCY9vBa4J718D/CKdzzn88MNdJCvNmOGen+9uFvycMSPqiFJatGhR2q+dMcM9L8896NkObnl5zftqS5cudcDnz5/v7u7nn3++33rrrb5lyxbv2bOnL1myxN3dzznnHL/99tv9s88+8759+3pVVZW7u69du9bd3X/84x/7rbfe6u7uxx57rL/yyis1+6h+/Omnn3qfPn1qto8ZM8bnzZvnixYt8rFjx/qXX37p7u4XX3yxP/jgg7Xi3LZtm/fu3dvd3a+44govKSnx+fPn+wsvvOATJ050d/eioiJ/4YUX3N39hhtu8Msvv7xm/xdffHHNZxUVFfnf//53d3e/8sor/bDDDnN390svvdRnhAfziy++8M2bN6d1DFP9DoFyT1GmtsYw0JkEi3L3M7OVZvZtgjVUTzKz94DR4WORtqu0FCoqoKoq+FlaGnVEzZapvu2DDjqIESNGAHD22Wczf/58lixZQu/evenbty8A5513HnPnzmWvvfaiU6dOfPvb3+bxxx8nL7mmVY8ePXpw8MEH8+KLL7JmzRreffddRowYwZw5c1i4cCFHHHEEgwcPZs6cOXz4Ye2lijt06ECfPn1YvHgxL7/8Mj/4wQ+YO3cu8+bNY+TIkaxfv55169Zx7LHH1oq32plnngnAunXrWLduHaNGjQLgnHPOqXnNUUcdxc9+9jNuueUWli1bRufOnZtwNOuX8cYndz+rjqdOzPS+RSRzMtW3nTyUsb6hjR06dODll19mzpw5zJ49m9/85jc891zyGvd1mzhxIrNmzaJ///6MHz8eM8PdOe+88/j5z39e73tHjRrFX/7yFzp27Mjo0aOZNGkSO3bs4NZbb21wv126dGnwNd/61rc48sgjeeqppzjllFP47W9/ywknnJD2d0uH5gISkSapqw+7uX3by5cvZ8GCBQA88sgjHHPMMfTr14+Kigref/99AB5++GGOPfZYNm7cyPr16znllFO4/fbbeeONN3b5vD322IMNGzak3Nf48eN54oknmDlzJhMnTgTgxBNPZPbs2Xz6adA1+fnnn7MsRSf+yJEjmTZtGkcddRQ9evRgzZo1LFmyhMLCQvbaay/23ntv5s2bVyveZN26daNbt27Mnz8fgLKETpQPP/yQgw8+mMsuu4xx48bx5ptvpn0M06UEICJNkqm+7X79+nHHHXcwYMAA1q5dy8UXX0ynTp24//77mTBhAkVFRbRr146LLrqIDRs2MHbsWIqLiznmmGOYOnXqLp83adIkLrrooppO4ER77703AwYMYNmyZQwbNgyAgQMH8tOf/pSTTz6Z4uJiTjrpJFavXr3L5x555JF88sknNc03xcXFFBUV1dRYHnzwQa666iqKi4t5/fXXufHGG1N+3/vvv59LLrmEwYMHV/eRAjBr1iwKCwsZPHgwb7/9Nueee27TDmg9smpN4JKSEteCMCKZs3jxYgYMGJD268vKgjb/5cuDM/8pU5rXvVFRUcHYsWN5++23G36xpJTqd2hmC929JPm1kV8HICLZq7S0TfRn5yw1AYlIbBQUFOjsvxUpAYiI5CglABGRHKUEICKSo5QARERylBKAiOSUdevWceedd9Y8XrVqFaeffnqEEdWvemK7TFACEJGckpwADjjgAGbPnh1hRDu5O1VVVa22PyUAEWm6Fp4PuqKiggEDBvCd73yHww47jJNPPrnm6t0PPviAMWPGcPjhhzNy5Ejefffdmu3Dhw+nqKiIH/3oR3Tt2hWAjRs3cuKJJzJ06FCKiop44okngGD66A8++IDBgwdz1VVX1VqEZfjw4bzzzjs18VRPHb1p0yYuuOAChg0bxpAhQ2o+K9Ell1zCk08+CQRTTFxwwQUA3HfffVwfzpA3depUCgsLKSwsZNq0aTXfuV+/fpx77rkUFhayYsUKpkyZQt++fTnmmGNYsmRJzT5+9atf1Ux9XT11RbOkmiI0rjdNBy2SWY2ZDjoT80EvXbrU27dv76+99pq7u0+YMMEffvhhd3c/4YQT/F//+pe7u7/44ot+/PHHu7v717/+dX/kkUfc3f2uu+7yLl26uHswZfP69evd3b2ystL79OnjVVVVvnTp0popl6v3Wf146tSpfuONN7q7+6pVq7xv377u7n7ttdfWxLF27Vo/9NBDfePGjbVinzlzpl955ZXu7n7EEUf4kUce6e7ukyZN8qefftrLy8u9sLDQN27c6Bs2bPCBAwf6q6++6kuXLnUz8wULFri717xu06ZNvn79eu/Tp0/N1Nb777+/b926tSaOVGI1HbSItFEZmg+6d+/eDB48GIDDDz+ciooKNm7cyD//+U8mTJhQs0hL9fw8CxYsYMKECUAwg2Y1d+e6666juLiY0aNH89FHH/HJJ5/Uu+8zzjijpjlo1qxZNX0DzzzzDDfffDODBw/muOOOY+vWrSxPmvZ05MiRzJs3j0WLFjFw4ED2228/Vq9ezYIFCzj66KOZP38+48ePp0uXLnTt2pXTTjutZrK4/Px8hg8fDsC8efMYP348eXl57Lnnnpx66qk1+yguLqa0tJQZM2a0yEpimgpCRJomQ/NB77777jX327dvz5YtW6iqqqJbt268/vrraX9OWVkZlZWVLFy4kI4dO1JQUMDWrVvrfc+BBx5I9+7defPNN/nd737H3XffDQTJ5LHHHqNfv371vnfdunU8/fTTjBo1is8//5xZs2bRtWtX9thjj3r3m8700ABPPfUUc+fO5U9/+hNTpkzhrbfealYiUA1ARJomU/NBp7DnnnvSu3dvfv/73wNBgVw99fPw4cN57LHHAHj00Udr3rN+/Xr23XdfOnbsyPPPP18zpXN900NDsFjLL37xC9avX09xcTEAX/3qV/n1r39dM1vna6+9lvK9w4cPZ9q0aYwaNYqRI0dy2223MXLkSCCoIfzxj39k8+bNbNq0iT/84Q81zyUaNWoUf/zjH9myZQsbNmzgT3/6EwBVVVWsWLGC448/nltuuYX169ezcePG9A9iCkoAItI0rbzWcVlZGffeey+DBg3isMMOq+mInTZtGlOnTqW4uJj333+fvfbaC4DS0lLKy8spKirioYceon///gB0796dESNGUFhYWGtN4Gqnn346jz76KGeccUbNthtuuIFt27ZRXFzMYYcdxg033JAyxpEjR7J9+3YOOeQQhg4dyueff15TyA8dOpRJkyYxbNgwjjzySC688EKGDBmyy2cMHTqUM888k0GDBvG1r32NI444AoAdO3Zw9tlnU1RUxJAhQ7jsssvo1q1b0w8omg5aRBI0djroFp8Pugk2b95M586dMTMeffRRZs6cmXKUTq7QdNAi0jpiMB/0woULufTSS3F3unXrxn333RdpPNkk0gRgZv8FXAg48BZwvrvX30sjIpJg5MiRKZeClIZF1gdgZgcClwEl7l4ItAda4MoGEWmObGoWltoa+7uLuhO4A9DZzDoAecCqiOMRyWmdOnVizZo1SgJZyN1Zs2YNnTp1Svs9kTUBuftHZnYbsBzYAjzj7s8kv87MJgOTAXplYHiZiOzUs2dPVq5cSWVlZdShSBN06tSJnj17pv36yEYBmdnewGPAmcA64PfAbHefUdd7NApIRKTx6hoFFGUT0GhgqbtXuvs24HHg6AjjERHJKVEmgOXAcDPLMzMDTgQWRxiPiEhOiSwBuPtLwGzgVYIhoO2A6VHFIyKSayIdBeTuP3b3/u5e6O7nuPsXUcYjLaSF54gXkczQlcDSssrKYPLkndMEL1sWPIbIrxgVkdqivg5A2poMzREvIi1PCUBaVobmiBeRlqcEIC2rFeeIF5HmUQKQltXKc8SLSNMpAUjLKi2F6dMhPx/Mgp/Tp6sDWCSGNApIWl4M5ogXkYapBiAikqOUAEREcpQSQFulq3FFpAHqA2iLdDWuiKRBNYC2SFfjikgalADaIl2NKyJpUAJoi3Q1roikQQmgLdLVuCKSBiWAtkhX44pIGjQKqK3S1bgi0gDVAEREcpQSgIhIjoo0AZhZNzObbWbvmtliMzsqynhERHJJ1H0AvwSedvfTzWw3IK+hN4iISMuILAGY2V7AKGASgLt/CXwZVTwiIrkmyiag3kAlcL+ZvWZm95hZl+QXmdlkMys3s/LKysrWj1JEpI2KMgF0AIYCd7n7EGATcE3yi9x9uruXuHtJjx49WjtGEZE2K8oEsBJY6e4vhY9nEyQEERFpBZElAHf/GFhhZv3CTScCi6KKR0Qk10Q9Cug/gbJwBNCHwPkRxyMikjMiTQDu/jpQEmUMIiK5SlcCi4jkKCUAEZEcpQQgIpKjlABERHKUEoCISI5SAhARyVFKACIiOUoJQEQkRykBiIjkKCUAEZEcpQQgIpKjlABERHKUEoCISI5SAhARyVFKACIiOUoJQEQkRykBiIjkKCUAEZEcpQQgIpKjIk8AZtbezF4zs/+NOhapX1kZFBRAu3bBz7KyqCMSkeaIdFH40OXAYmDPqAORupWVweTJsHlz8HjZsuAxQGlpdHGJSNNFWgMws57A14F7ooxDGnb99TsL/2qbNwfbRSQ7Rd0ENA24GqiKOA5pwPLljdsuIvEXWQIws7HAp+6+sIHXTTazcjMrr6ysbKXoJFmvXo3bLiLxF2UNYARwqplVAI8CJ5jZjOQXuft0dy9x95IePXq0dowSmjIF8vJqb8vLC7aLSHaKLAG4+7Xu3tPdC4CJwHPufnZU8TRZjgyNKS2F6dMhPx/Mgp/Tp6sDWCSbxWEUUPbKsaExpaVt8muJ5Cxz96hjSFtJSYmXl5dHHcZOBQVBoZ8sPx8qKlo7GhGRlMxsobuXJG+PehRQLKXdqqOhMSKSxZQAklS36ixbBu47W3VSJgENjRGRLKYEkKRRFzxpaIyIZDElgCSNatXR0BgRyWJKAEka3apTWhp0+FZVBT9V+IvktiwaGq4EkEStOiLSZI3qRIyeEkASteqISJNl2ayJug5ARKSltGsXnPknMwuaiSPS5OsAzOw/zWzvzIQlItKGZNnQ8HSagPYDXjGzWWY2xsws00GJiGSlLOtEbDABuPuPgEOBe4FJwHtm9jMz65Ph2EREskuWdSKmNRmcu7uZfQx8DGwH9gZmm9mz7n51JgMUEckqWTRrYoMJwMwuB84FPiNYuvEqd99mZu2A9whW9BIRkSyTTg3gK8Bp7l5r2kt3rwpX9RIRkSzUYAJw9x/X89zilg1HRERaiy4EExHJUUoAIiI5SglARCRHKQGIiOQoJQARkRwVWQIws4PM7HkzW2Rm74TXG4iISCuJsgawHbjC3QcCw4FLzGxghPHETxYtLCEi2SetqSAywd1XA6vD+xvMbDFwILAoqphipXphieq5xasXloCsucxcROItFn0AZlYADAFeSvHcZDMrN7PyysrKVo8tMnUsLFFx9vWqDIhIi4g8AZhZV+Ax4Pvu/u/k5919uruXuHtJjx49Wj/AqNSxOn0vlsd9lTkRyRKRJgAz60hQ+Je5++NRxhI7dSwgsZxge4xXmRORLBHlKCAjWGNgsbtPjSqO2EqxsMQm8riOnQtL1FFJEBFJS5Q1gBHAOcAJZvZ6eDslwnjiJWFhiSqMCvL5DtOZyc4O4JiuMiciWSLKUUDzAS0vWZ9wYYmZSQOCINarzIlIloi8E1galmWrzIlIloisBiCNk0WrzIlIllANQEQkR7X5BKDZFEREUmvTTUCaTUFEpG5tugZQx2wKuoBKWo6qmJLF2nQCqOtCqThcQPW970GHDsGong4dgseSZaqrmMuWgTuao0OyTZtOAHVdKBX1BVTf+x7cdRfs2BE83rEjeBzXJKCT3Dqoipk9mvNH3Jb/Adw9a26HH364N8aMGe55ee7B6Vlwy8sLtkepffvaMVXf2rdv/GfNmOGen+9uFvxs6e8W12MYC2apf5FmUUcmiZrzR9xG/gGAck9RpkZeqDfm1tgE4J75ArIpksuLs5jhS8n3HTQuyNb428zPT13G5ee33D6ylg5OdmjO76mN/I7rSgAWPJcdSkpKvLy8POowmq1Dh53NP2dRxv8wmS4kzfOQxqW+BQVBs3Oy/HyoqGiZWNu1C/7ik5lBVVXL7CNrJQ8zg7R/d9KKmvNH3Eb+AcxsobuXJG9v030AcVU9FBXgZ1xfu/CHtNuRW6OTO679KLGgOTqyQ3P+iNv4P4ASQATuvBMuvhjatw8WeEkpjVK8Nf42U8xKHeuJ6Fq9v660NKhuVVUFP1X4x09z/oiz7R+gsVK1C8X11pQ+gNhrRhtja/VPxbEfJZU20l8nmdCcP+Js+QeoB+oDiKlmtiOXlQWtRcuXB2f+U6bk7kloa/SJiGSjuvoAlADiQKV4i2gj/XUiLU6dwHEW93bkLLkQpo3314m0OCUAqV8WTXfQ1vvrRFqaEoDUL4umO9CoTJHGibQPwMzGAL8E2gP3uPvN9b2+zfYBxJka1kWyXuz6AMysPXAH8DVgIHCWmQ2MKp64i6wZXg3rIm1WlE1Aw4D33f1Dd/8SeBQYF2E8sRVpM7wa1kXarCgTwIHAioTHK8NttZjZZDMrN7PyysrKVgksboNeIm2GV8O6SJsV+yUh3X06MB2CPoBM7y+Oy0hGvrBNaakKfJE2KMoawEfAQQmPe4bbIhXHQS9xaIaPW61IRJovygTwCnComfU2s92AicCTEcYDxOBsO4UGm+EzXDpn0aUAItIIkSUAd98OXAr8FVgMzHL3d6KKp1pGzrabWUDX2wzfCqVzHGtFItJ8mgsoSYuv8ZHpRUNaYQY0XQogkt1idx1AXLX4oJcWPn1Orkz4ssy3WcWhD0JEWp4SQAotOjdbczsVEkr8jfsU8Lfzy2q19qywzJfOuhRApG1SAmhAs/tXm3P6nNS+33XNMn6zbTJnsTOIa3wKmy3N0rmJX0aXAoi0UalWiYnrrbVXBGuRFaaa8yF1rBa2lPxam75FGisWabkskZxFHSuCRV6oN+bW2gmgGas11tbUJeXMUgawA2t8PC32ZSLQBpbkE4lSXQlATUD1aLFrApraqVBHM9Fydm6vty0+sckn1Ugh2Pll4nqlly5CEMkYJYB6RD76JUXv6/bd8pjafUrDbfHJBWddevWKdyGrixBEMkYJoB6Rj35J0fva4b7p/Oqz0oYrE6kKzmTVXybOhWwcL80WaSOUAOoRi9EvTW0+qq+ATP4ycS5kI6+GibRdSgANiPt67XWqq4DMz9/1y2SykG1u30Lk1TCRtksJoK1qTMGZqUK2JfoWYlENE2mbNBdQW1ZWFrTjL18enM1PmVJ3wdmY16arFeYpEpGGaS6gGGj1kZaNab/KRFtXXX0Iy5bFb7ipSA5SAmglcR5pmTH19SHkzEEQiS8lgFYS+UjLKC70StW3kCwuw01FcpASQCuJdKRlS1Q/mpJAkjtw61C1bLlag0QioATQSiIdzt7c6kdzEkhi30J+fsqXLKeXWoNEIqAE0EoiHc7e1OpH9Vn/2Wenl0AaqiWkOAibyOM6ptT5kSKSQalmiIvrrbVnA21pkU1q2ZSZQFNNH518M6v/9ammmw4Pwg7Ml5LvZzGjzo8UkZZBHbOBRnIdgJndCnwD+BL4ADjf3dc19D5dB9BEjViXuPpygBeWFVBAHTOIVkscz9/IMf+6RECk9cTtOoBngUJ3Lwb+BVwbURy5Ic2raROb+nvRQPNQcvtVI5uZNMODSPQiSQDu/oy7bw8fvgj0jCKOnJLGhV6JfcWJaw7sIlUCaWQvt2Z4EIleHDqBLwD+UteTZjbZzMrNrLyysrIVw8o9iSfr1zGFTaQ4RZ8xI3UCacIpfdZOtCfSRmQsAZjZ38zs7RS3cQmvuR7YDtQ5+M/dp7t7ibuX9OjRI1PhCrVP1mdSyneYTgX5VJHGKbpO6UWyTmSTwZnZJOC7wInu3sDKJQF1AmdWI/qKRSSLxKoT2MzGAFcDp6Zb+Evm6SReJHPiuOx2VMNA3wd2B9aEm15094saep9qACKSjaKuXddVA9B6ACIiGRb1dS+xagISEcklcV12WwlAgHi2T4q0FZFOBlkPJQDJzcVqRFpRXK98VwKQllmsRlUIkTrFdYSdEoA0v31SVQiRBjX1yvdMnlspAUjz2ycjX+9SpG3K9LmVEoA0v30yrkMcRLJcps+tlACk+e2TcR3iIJLlMn1upQQgQDNn5ozpEAf1S0u2y/S5lRKANF8MhzioX1ragkyfWykBSEqNPnuO2eT+6peWtiDT51aaC0h2EfXEVS2hXbvgzD+ZWZCjRHKJ5gKStLWFs2f1S4s0TAlAdtEWRnXGtF9aJFaUAGQX6Z49x3mUTQz7pUViRwlAdpHO2XM2jLKJWb+0SOwoAeSIxpytp3P23Bb6CURynUYB5YBMjOrRKBuR7KFRQDksE2frGmUjkv0iTQBmdoWZuZntE2UcbV0mRvVolI1I9ossAZjZQcDJQBYNLsxOmThb1ygbkewXZQ3gduBqIHs6IbLUKac0bnu6NMpGJLtFkgDMbBzwkbu/kcZrJ5tZuZmVV1ZWtkJ0bc+f/9y47SKSGzpk6oPN7G/Af6R46nrgOoLmnwa5+3RgOgSjgFoswBzSFq7sFZGWl7EE4O6jU203syKgN/CGmQH0BF41s2Hu/nGm4sllvXoFF2ql2i4iuavVm4Dc/S1339fdC9y9AFgJDFXhnzkasSMiqeg6gBygETsikkrGmoDSFdYCJMNKS1Xgi0htqgGIiOQoJQARkRylBCAikqOUAEREcpQSgIhIjsqq9QDMrBJIcUlTxuwDfNaK+2sMxdY0cY0trnGBYmuKuMWV7+49kjdmVQJobWZWnmoRhThQbE0T19jiGhcotqaIa1zJ1AQkIpKjlABERHKUEkD9pkcdQD0UW9PENba4xgWKrSniGlct6gMQEclRqgGIiOQoJQARkRylBJAmM7vCzNzM9ok6lmpmdquZvWtmb5rZH8ysW8TxjDGzJWb2vpldE2UsiczsIDN73swWmdk7ZnZ51DElM7P2Zvaamf1v1LFUM7NuZjY7/BtbbGZHRR1TNTP7r/B3+baZzTSzThHGcp+ZfWpmbyds+4qZPWtm74U/944qvvooAaTBzA4iWMIybosoPgsUunsx8C/g2qgCMbP2wB3A14CBwFlmNjCqeJJsB65w94HAcOCSGMVW7XJgcdRBJPkl8LS79wcGEZP4zOxA4DKgxN0LgfbAxAhDegAYk7TtGmCOux8KzAkfx44SQHpuB64GYtVj7u7PuPv28OGLBMtrRmUY8L67f+juXwKPAuMijKeGu69291fD+xsICrIDo41qJzPrCXwduCfqWKqZ2V7AKOBeAHf/0t3XRRpUbR2AzmbWAcgDVkUViLvPBT5P2jwOeDC8/yDwzdaMKV1KAA0ws3HAR+7+RtSxNOAC4C8R7v9AYEXC45XEqJCtZmYFwBDgpYhDSTSN4ASjKuI4EvUGKoH7w6ape8ysS9RBAbj7R8BtBDXy1cB6d38m2qh2sZ+7rw7vfwzsF2UwdVECAMzsb2FbYvJtHHAdcGNMY6t+zfUEzRxlUcWZDcysK/AY8H13/3fU8QCY2VjgU3dfGHUsSToAQ4G73H0IsImYNGOE7enjCJLUAUAXMzs72qjq5sFY+1i1HlSLfEnIOHD30am2m1kRwR/ZG2YGQRPLq2Y2rLUWsa8rtmpmNgkYC5zo0V7U8RFwUMLjnuG2WDCzjgSFf5m7Px51PAlGAKea2SlAJ2BPM5vh7lEXaCuBle5eXVOaTUwSADAaWOrulQBm9jhwNDAj0qhq+8TM9nf31Wa2P/Bp1AGlohpAPdz9LXff190LwrWLVwJDW6vwb4iZjSFoOjjV3TdHHM4rwKFm1tvMdiPolHsy4pgAsCB73wssdvepUceTyN2vdfee4d/XROC5GBT+hH/jK8ysX7jpRGBRhCElWg4MN7O88Hd7IjHpoE7wJHBeeP884IkIY6mTagDZ7TfA7sCzYQ3lRXe/KIpA3H27mV0K/JVgVMZ97v5OFLGkMAI4B3jLzF4Pt13n7n+OLqSs8J9AWZjQPwTOjzgeANz9JTObDbxK0PT5GhFOvWBmM4HjgH3MbCXwY+BmYJaZfZtgCvszooqvPpoKQkQkR6kJSEQkRykBiIjkKCUAEZEcpQQgIpKjlABERHKUEoCISI5SAhARyVFKACLNYGZHhOsxdDKzLuEc9YVRxyWSDl0IJtJMZvZTgnl8OhPMn/PziEMSSYsSgEgzhVMlvAJsBY529x0RhySSFjUBiTRfd6ArsAdBTUAkK6gGINJMZvYkwQpovYH93f3SiEMSSYtmAxVpBjM7F9jm7o+E6yL/08xOcPfnoo5NpCGqAYiI5Cj1AYiI5CglABGRHKUEICKSo5QARERylBKAiEiOUgIQEclRSgAiIjnq/wAYJtK9hhADUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(positive.pc_one, positive.pc_two, color='b')\n",
    "plt.scatter(negative.pc_one, negative.pc_two, color='r')\n",
    "plt.legend(['positive words', 'negative words'], loc ='upper right')\n",
    "plt.title('Reduced Word Embeddings')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24695d4e-adeb-4fbe-8deb-d93b1dd57918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_words(data):\n",
    "    \"\"\"\n",
    "    Function to compare a word to other words in a pandas dataframe.\n",
    "    \"\"\"\n",
    "    similarities = {}\n",
    "    for i in range(len(data)):\n",
    "        current_embedding = data.loc[i].word_embeddings.reshape(1, -1)\n",
    "        current_word = data.loc[i].word\n",
    "        most_similar = 0\n",
    "        for j in range(len(data)):\n",
    "            other_embedding = data.loc[j].word_embeddings.reshape(1, -1)\n",
    "            other_word = data.loc[j].word\n",
    "            similarity = cosine_similarity(current_embedding, other_embedding)\n",
    "            if similarity >= most_similar and current_word != other_word:\n",
    "                similarities[current_word] = other_word\n",
    "                most_similar = similarity\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f8167b-ea81-404c-9739-703e9b392ba0",
   "metadata": {},
   "source": [
    "# TODO: Explain the similarities below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd64b3f8-6bdf-4456-8da8-7ca8c64f4729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 'hate',\n",
       " 'terrific': 'wonderful',\n",
       " 'admired': 'courageous',\n",
       " 'jolly': 'lively',\n",
       " 'brave': 'courageous',\n",
       " 'fun': 'nice',\n",
       " 'engaged': 'courageous',\n",
       " 'happy': 'sad',\n",
       " 'wonderful': 'amazing',\n",
       " 'hopeful': 'frustrated',\n",
       " 'free': 'frustrated',\n",
       " 'confident': 'frustrated',\n",
       " 'secure': 'confident',\n",
       " 'lively': 'jolly',\n",
       " 'amazing': 'awesome',\n",
       " 'friendly': 'failure',\n",
       " 'awesome': 'amazing',\n",
       " 'beautiful': 'amazing',\n",
       " 'kind': 'frustrated',\n",
       " 'strong': 'helpless',\n",
       " 'joyful': 'happy',\n",
       " 'courageous': 'brave',\n",
       " 'carefree': 'joyful',\n",
       " 'nice': 'strong',\n",
       " 'rejected': 'admired',\n",
       " 'afraid': 'scared',\n",
       " 'regretful': 'displeased',\n",
       " 'coward': 'helpless',\n",
       " 'embarrassed': 'disgusted',\n",
       " 'sad': 'lonely',\n",
       " 'lonely': 'frustrated',\n",
       " 'alone': 'lonely',\n",
       " 'displeased': 'disgusted',\n",
       " 'panic': 'terrified',\n",
       " 'terrified': 'scared',\n",
       " 'loser': 'failure',\n",
       " 'frustrated': 'scared',\n",
       " 'lost': 'loser',\n",
       " 'feeble': 'displeased',\n",
       " 'failure': 'rejected',\n",
       " 'helpless': 'terrified',\n",
       " 'disgusted': 'embarrassed',\n",
       " 'ugly': 'disgusting',\n",
       " 'horrible': 'terrible',\n",
       " 'unhappy': 'frustrated',\n",
       " 'disgusting': 'horrible',\n",
       " 'terrible': 'horrible',\n",
       " 'scared': 'terrified',\n",
       " 'hate': 'frustrated'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = compare_words(data)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ea84339-2d13-46cb-b6b8-1af659456ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 49 nearest neighbors...\n",
      "[t-SNE] Indexed 50 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 50 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 50 / 50\n",
      "[t-SNE] Mean sigma: 5.554680\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 49.597054\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.430304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gael Gil\\Desktop\\git-repos\\notebooks\\book_genre_comparison\\env\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Gael Gil\\Desktop\\git-repos\\notebooks\\book_genre_comparison\\env\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, random_state=123)\n",
    "z = tsne.fit_transform(list(data.word_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2466d2d4-0ea9-41ad-b7ad-b4a2903ddb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "# get our first component\n",
    "df[\"comp_one\"] = z[:,0]\n",
    "# get our second component\n",
    "df[\"comp_two\"] = z[:,1]\n",
    "# add our reduced data into our dataframe\n",
    "data = pd.concat([data, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93060483-8302-4d97-a087-6b5ba072c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = data.query('label.str.contains(\"positive\")', engine='python')\n",
    "negative = data.query('label.str.contains(\"negative\")', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbedb6-b1e7-453e-b9c9-daa905814aa6",
   "metadata": {},
   "source": [
    "Below I have graphed our data in its reduced form by tsne. # TODO: Finish explaning the graph below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58f6f3df-95c5-4e03-9775-9e8947dcdaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(positive.comp_one, positive.comp_two, color='b')\n",
    "plt.scatter(negative.comp_one, negative.comp_two, color='r')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4396e3-4d30-40ac-a269-22c17dce8a60",
   "metadata": {},
   "source": [
    "# Using the Book Dataset\n",
    "Now we are going to attempt to see if we can try and do the same for a whole book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "575b451d-2846-4084-8512-71fab9d3984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('./data/csv/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1052684-6858-4ae4-88e2-7beb9f0fd245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/cook_book_one.txt</td>\n",
       "      <td>project gutenberg's the whitehouse cookbook by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/cook_book_three.txt</td>\n",
       "      <td>the project gutenberg ebook of new royal cook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/gothic_novel_four.txt</td>\n",
       "      <td>the project gutenberg ebook of the works of ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/gothic_novel_six.txt</td>\n",
       "      <td>the project gutenberg ebook of northanger abbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/gothic_novel_two.txt</td>\n",
       "      <td>project gutenberg’s the complete works of will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./data/gothic_novel_three.txt</td>\n",
       "      <td>the project gutenberg ebook of dracula by bram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./data/cook_book_four.txt</td>\n",
       "      <td>the project gutenberg ebook of the italian coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./data/gothic_novel_ten.txt</td>\n",
       "      <td>the project gutenberg ebook of the castle of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./data/gothic_novel_eight.txt</td>\n",
       "      <td>the project gutenberg ebook of the vampyre a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./data/gothic_novel_nine.txt</td>\n",
       "      <td>the project gutenberg ebook of the masque of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./data/cook_book.txt</td>\n",
       "      <td>the project gutenberg ebook of california mexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./data/cook_book_ten.txt</td>\n",
       "      <td>the project gutenberg ebook of seventy five re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./data/cook_book_nine.txt</td>\n",
       "      <td>the project gutenberg ebook of mrs wilson's co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./data/cook_book_eight.txt</td>\n",
       "      <td>the project gutenberg ebook of a plain cookery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./data/gothic_novel.txt</td>\n",
       "      <td>the project gutenberg ebook of the phantom of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./data/gothic_novel_five.txt</td>\n",
       "      <td>the project gutenberg ebook of the woman in wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./data/cook_book_six.txt</td>\n",
       "      <td>the project gutenberg ebook of twenty five cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./data/cook_book_two.txt</td>\n",
       "      <td>the project gutenberg ebook old cookery books ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./data/gothic_novel_seven.txt</td>\n",
       "      <td>the project gutenberg ebook of frankenstein by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./data/gothic_novel_one.txt</td>\n",
       "      <td>the project gutenberg ebook of the works of ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./data/cook_book_seven.txt</td>\n",
       "      <td>the project gutenberg ebook of the belgian coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./data/cook_book_five.txt</td>\n",
       "      <td>project gutenberg's the complete book of chees...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             book  \\\n",
       "0        ./data/cook_book_one.txt   \n",
       "1      ./data/cook_book_three.txt   \n",
       "2    ./data/gothic_novel_four.txt   \n",
       "3     ./data/gothic_novel_six.txt   \n",
       "4     ./data/gothic_novel_two.txt   \n",
       "5   ./data/gothic_novel_three.txt   \n",
       "6       ./data/cook_book_four.txt   \n",
       "7     ./data/gothic_novel_ten.txt   \n",
       "8   ./data/gothic_novel_eight.txt   \n",
       "9    ./data/gothic_novel_nine.txt   \n",
       "10           ./data/cook_book.txt   \n",
       "11       ./data/cook_book_ten.txt   \n",
       "12      ./data/cook_book_nine.txt   \n",
       "13     ./data/cook_book_eight.txt   \n",
       "14        ./data/gothic_novel.txt   \n",
       "15   ./data/gothic_novel_five.txt   \n",
       "16       ./data/cook_book_six.txt   \n",
       "17       ./data/cook_book_two.txt   \n",
       "18  ./data/gothic_novel_seven.txt   \n",
       "19    ./data/gothic_novel_one.txt   \n",
       "20     ./data/cook_book_seven.txt   \n",
       "21      ./data/cook_book_five.txt   \n",
       "\n",
       "                                                words  \n",
       "0   project gutenberg's the whitehouse cookbook by...  \n",
       "1   the project gutenberg ebook of new royal cook ...  \n",
       "2   the project gutenberg ebook of the works of ed...  \n",
       "3   the project gutenberg ebook of northanger abbe...  \n",
       "4   project gutenberg’s the complete works of will...  \n",
       "5   the project gutenberg ebook of dracula by bram...  \n",
       "6   the project gutenberg ebook of the italian coo...  \n",
       "7   the project gutenberg ebook of the castle of o...  \n",
       "8   the project gutenberg ebook of the vampyre a t...  \n",
       "9   the project gutenberg ebook of the masque of t...  \n",
       "10  the project gutenberg ebook of california mexi...  \n",
       "11  the project gutenberg ebook of seventy five re...  \n",
       "12  the project gutenberg ebook of mrs wilson's co...  \n",
       "13  the project gutenberg ebook of a plain cookery...  \n",
       "14  the project gutenberg ebook of the phantom of ...  \n",
       "15  the project gutenberg ebook of the woman in wh...  \n",
       "16  the project gutenberg ebook of twenty five cen...  \n",
       "17  the project gutenberg ebook old cookery books ...  \n",
       "18  the project gutenberg ebook of frankenstein by...  \n",
       "19  the project gutenberg ebook of the works of ed...  \n",
       "20  the project gutenberg ebook of the belgian coo...  \n",
       "21  project gutenberg's the complete book of chees...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbe3d8-0d74-42a6-a4e1-9b799db6f32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
