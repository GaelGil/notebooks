{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5329f1c-a112-4676-b7d6-d7da89d69875",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "<!-- In this notebook I will visualize the similarities of two kinds of books. The two kinds of books I am chossing to compare are cook books and gothic/horror books. I am going to visualize both these books by graphing them. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b0c16-d042-46b3-a99b-ae98fc2cd282",
   "metadata": {},
   "source": [
    "# The Data\n",
    "To demonstrate this I will first start by using a small dataset that I created. The data can be found in the `./data/csv` folder. It consists of two columns (word, label). Here are two examples `word=love,label=positive, word=hate,label=negative`. I will put this through the bert model to get an embedding and then use a dimensionalty reduction algorithm to plot each word.  \n",
    "\n",
    "Later on I will be using book data. This data has two columns. I got this data from [here](https://www.gutenberg.org/)\n",
    "\n",
    "First we will import some useful tools that will help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4912f135-7f92-4522-8e44-72ba2ab74374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gael/git-repos/notebooks/book_genre_detection/env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b6f46-a0b2-4156-8099-ab05da70675e",
   "metadata": {},
   "source": [
    "# First Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22075b8-aeb9-4923-98a4-21a77e1ded4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/csv/words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864f56ef-500e-4812-86d3-5e6242a22020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terrific</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admired</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jolly</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brave</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     label\n",
       "0      love  positive\n",
       "1  terrific  positive\n",
       "2   admired  positive\n",
       "3     jolly  positive\n",
       "4     brave  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4068b662-cb69-4691-b0ac-3a70d148fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368c8384-2a91-494b-a416-0190e2a3005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize every word in the dataframe\n",
    "encoded_data = [tokenizer(i, return_tensors='pt') for i in data.word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc138070-ef87-4b3a-95b0-cb587116d081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2293,  102]]), 'token_type_ids': tensor([[0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our words have been encoded into a list of ids that look like this: tensor([[ 101, 3866,  102]]). \n",
    "# 101 and 102 are for start and stop. 3866 is the id of our actual word embedding and its what we actually\n",
    "# need. We will extract this later.\n",
    "encoded_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af9f59d6-f391-4166-897a-e0f758547c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word embedding for each word in our dataset\n",
    "word_embeddings = [model(**i) for i in encoded_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf004c6-f9ef-4716-a57c-479106e85665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings[0].last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc2ccff-9da3-4f1c-ba8b-d2c459fd306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last hidden state for each of the embeddings\n",
    "embeddings = [i.last_hidden_state for i in word_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffdad094-4b12-49e4-9cc9-2388812b5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual word embeddings\n",
    "embeddings = [i[0][1] for i in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cce1c06-9584-44dc-9bd6-b46bb2dddd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [i.detach().numpy() for i in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c28e6ff9-a44e-471f-b305-87e840d73f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the embeddings to our dataframe\n",
    "data['word_embeddings'] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edeea62-bf47-4eaf-86c1-48f22308198c",
   "metadata": {},
   "source": [
    "# Visualizing\n",
    "\n",
    "Before we care able to visualize our data. we see below that the word_embeddings are huge vectors. This means we can't visulize this so we are going to use a dimensionality reduction algorithm. For this I am going to use PCA (principal component analysis) to reduce the dimension to two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9b2ffc3-067b-4bc5-94c1-da2bd7ddae67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>word_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.38649088, 0.36188114, 0.23423344, -0.395798...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terrific</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.33330074, -0.20869645, -0.1652221, -0.06318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admired</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.25650117, 0.022439487, 0.25480837, -0.0880...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jolly</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.22022378, -0.20243269, 0.10135959, -0.3264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brave</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.08306722, -0.11899652, -0.46022692, -0.438...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     label                                    word_embeddings\n",
       "0      love  positive  [0.38649088, 0.36188114, 0.23423344, -0.395798...\n",
       "1  terrific  positive  [0.33330074, -0.20869645, -0.1652221, -0.06318...\n",
       "2   admired  positive  [-0.25650117, 0.022439487, 0.25480837, -0.0880...\n",
       "3     jolly  positive  [-0.22022378, -0.20243269, 0.10135959, -0.3264...\n",
       "4     brave  positive  [-0.08306722, -0.11899652, -0.46022692, -0.438..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "049c4eba-1a26-4bdb-a754-9400e4b44c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(list(data.word_embeddings))\n",
    "principal_df = pd.DataFrame(data = principal_components, columns=['pc_one', 'pc_two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9172a977-1c8d-4e5a-8772-ec08457363eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc_one</th>\n",
       "      <th>pc_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.714285</td>\n",
       "      <td>0.511766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.681742</td>\n",
       "      <td>-3.310150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.780253</td>\n",
       "      <td>0.753348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.881724</td>\n",
       "      <td>-0.769091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.737804</td>\n",
       "      <td>0.931430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pc_one    pc_two\n",
       "0  1.714285  0.511766\n",
       "1 -0.681742 -3.310150\n",
       "2 -1.780253  0.753348\n",
       "3 -3.881724 -0.769091\n",
       "4 -2.737804  0.931430"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28101e0a-6f77-4665-b66e-5f3e3665f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add our reduced data to our main dataframe\n",
    "data = pd.concat([data, principal_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f3918c1-9481-4fc5-83d9-89c60efca0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>word_embeddings</th>\n",
       "      <th>pc_one</th>\n",
       "      <th>pc_two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.38649088, 0.36188114, 0.23423344, -0.395798...</td>\n",
       "      <td>1.714285</td>\n",
       "      <td>0.511766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terrific</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.33330074, -0.20869645, -0.1652221, -0.06318...</td>\n",
       "      <td>-0.681742</td>\n",
       "      <td>-3.310150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>admired</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.25650117, 0.022439487, 0.25480837, -0.0880...</td>\n",
       "      <td>-1.780253</td>\n",
       "      <td>0.753348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jolly</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.22022378, -0.20243269, 0.10135959, -0.3264...</td>\n",
       "      <td>-3.881724</td>\n",
       "      <td>-0.769091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brave</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.08306722, -0.11899652, -0.46022692, -0.438...</td>\n",
       "      <td>-2.737804</td>\n",
       "      <td>0.931430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     label                                    word_embeddings  \\\n",
       "0      love  positive  [0.38649088, 0.36188114, 0.23423344, -0.395798...   \n",
       "1  terrific  positive  [0.33330074, -0.20869645, -0.1652221, -0.06318...   \n",
       "2   admired  positive  [-0.25650117, 0.022439487, 0.25480837, -0.0880...   \n",
       "3     jolly  positive  [-0.22022378, -0.20243269, 0.10135959, -0.3264...   \n",
       "4     brave  positive  [-0.08306722, -0.11899652, -0.46022692, -0.438...   \n",
       "\n",
       "     pc_one    pc_two  \n",
       "0  1.714285  0.511766  \n",
       "1 -0.681742 -3.310150  \n",
       "2 -1.780253  0.753348  \n",
       "3 -3.881724 -0.769091  \n",
       "4 -2.737804  0.931430  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e0ccaee-3e05-439e-bb35-6f87aced5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the words by label\n",
    "positive = data.query('label.str.contains(\"positive\")', engine='python')\n",
    "negative = data.query('label.str.contains(\"negative\")', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367fe23-43f8-4a11-a173-914b31a43398",
   "metadata": {},
   "source": [
    "<!-- Below we is a graph of our words graphed. We can see that the positive words are on the upper left of the chart and the negative words are in the middle to the right of the positive words. We can also see that they slightly overlap in the middle. We can also see that there are words that -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ee949d1-cced-4a2a-8839-3b93ab90d245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(positive.pc_one, positive.pc_two, color='b')\n",
    "plt.scatter(negative.pc_one, negative.pc_two, color='r')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24695d4e-adeb-4fbe-8deb-d93b1dd57918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_words(data):\n",
    "    \"\"\"\n",
    "    Function to compare a word to other words in a pandas dataframe.\n",
    "    \"\"\"\n",
    "    similarities = {}\n",
    "    for i in range(len(data)):\n",
    "        current_embedding = data.loc[i].word_embeddings.reshape(1, -1)\n",
    "        current_word = data.loc[i].word\n",
    "        most_similar = 0\n",
    "        for j in range(len(data)):\n",
    "            other_embedding = data.loc[j].word_embeddings.reshape(1, -1)\n",
    "            other_word = data.loc[j].word\n",
    "            similarity = cosine_similarity(current_embedding, other_embedding)\n",
    "            if similarity >= most_similar and current_word != other_word:\n",
    "                similarities[current_word] = other_word\n",
    "                most_similar = similarity\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3c3aaf6-bf25-491d-804e-0252c05e77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = compare_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36422b86-cca8-47cd-8425-0cdde1e1bc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 'hate',\n",
       " 'terrific': 'wonderful',\n",
       " 'admired': 'courageous',\n",
       " 'jolly': 'lively',\n",
       " 'brave': 'courageous',\n",
       " 'fun': 'nice',\n",
       " 'engaged': 'courageous',\n",
       " 'happy': 'sad',\n",
       " 'wonderful': 'amazing',\n",
       " 'hopeful': 'frustrated',\n",
       " 'free': 'frustrated',\n",
       " 'confident': 'frustrated',\n",
       " 'secure': 'confident',\n",
       " 'lively': 'jolly',\n",
       " 'amazing': 'awesome',\n",
       " 'friendly': 'failure',\n",
       " 'awesome': 'amazing',\n",
       " 'beautiful': 'amazing',\n",
       " 'kind': 'frustrated',\n",
       " 'strong': 'helpless',\n",
       " 'joyful': 'happy',\n",
       " 'courageous': 'brave',\n",
       " 'carefree': 'joyful',\n",
       " 'nice': 'strong',\n",
       " 'rejected': 'admired',\n",
       " 'afraid': 'scared',\n",
       " 'regretful': 'displeased',\n",
       " 'coward': 'helpless',\n",
       " 'embarrassed': 'disgusted',\n",
       " 'sad': 'lonely',\n",
       " 'lonely': 'frustrated',\n",
       " 'alone': 'lonely',\n",
       " 'displeased': 'disgusted',\n",
       " 'panic': 'terrified',\n",
       " 'terrified': 'scared',\n",
       " 'loser': 'failure',\n",
       " 'frustrated': 'scared',\n",
       " 'lost': 'loser',\n",
       " 'feeble': 'displeased',\n",
       " 'failure': 'rejected',\n",
       " 'helpless': 'terrified',\n",
       " 'disgusted': 'embarrassed',\n",
       " 'ugly': 'disgusting',\n",
       " 'horrible': 'terrible',\n",
       " 'unhappy': 'frustrated',\n",
       " 'disgusting': 'horrible',\n",
       " 'terrible': 'horrible',\n",
       " 'scared': 'terrified',\n",
       " 'hate': 'frustrated'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dad589-48d4-4461-8068-881afc9dd2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39742d88-c26a-45fe-85c8-1058d2c6f636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db4396e3-4d30-40ac-a269-22c17dce8a60",
   "metadata": {},
   "source": [
    "# Using the Book Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "575b451d-2846-4084-8512-71fab9d3984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/csv/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1052684-6858-4ae4-88e2-7beb9f0fd245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/cook_book_one.txt</td>\n",
       "      <td>project gutenberg's the whitehouse cookbook by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/cook_book_three.txt</td>\n",
       "      <td>the project gutenberg ebook of new royal cook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/gothic_novel_four.txt</td>\n",
       "      <td>the project gutenberg ebook of the works of ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/gothic_novel_six.txt</td>\n",
       "      <td>the project gutenberg ebook of northanger abbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/gothic_novel_two.txt</td>\n",
       "      <td>project gutenberg’s the complete works of will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./data/gothic_novel_three.txt</td>\n",
       "      <td>the project gutenberg ebook of dracula by bram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./data/cook_book_four.txt</td>\n",
       "      <td>the project gutenberg ebook of the italian coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./data/gothic_novel_ten.txt</td>\n",
       "      <td>the project gutenberg ebook of the castle of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./data/gothic_novel_eight.txt</td>\n",
       "      <td>the project gutenberg ebook of the vampyre a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./data/gothic_novel_nine.txt</td>\n",
       "      <td>the project gutenberg ebook of the masque of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./data/cook_book.txt</td>\n",
       "      <td>the project gutenberg ebook of california mexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./data/cook_book_ten.txt</td>\n",
       "      <td>the project gutenberg ebook of seventy five re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./data/cook_book_nine.txt</td>\n",
       "      <td>the project gutenberg ebook of mrs wilson's co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./data/cook_book_eight.txt</td>\n",
       "      <td>the project gutenberg ebook of a plain cookery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./data/gothic_novel.txt</td>\n",
       "      <td>the project gutenberg ebook of the phantom of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./data/gothic_novel_five.txt</td>\n",
       "      <td>the project gutenberg ebook of the woman in wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./data/cook_book_six.txt</td>\n",
       "      <td>the project gutenberg ebook of twenty five cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./data/cook_book_two.txt</td>\n",
       "      <td>the project gutenberg ebook old cookery books ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./data/gothic_novel_seven.txt</td>\n",
       "      <td>the project gutenberg ebook of frankenstein by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./data/gothic_novel_one.txt</td>\n",
       "      <td>the project gutenberg ebook of the works of ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./data/cook_book_seven.txt</td>\n",
       "      <td>the project gutenberg ebook of the belgian coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./data/cook_book_five.txt</td>\n",
       "      <td>project gutenberg's the complete book of chees...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             book  \\\n",
       "0        ./data/cook_book_one.txt   \n",
       "1      ./data/cook_book_three.txt   \n",
       "2    ./data/gothic_novel_four.txt   \n",
       "3     ./data/gothic_novel_six.txt   \n",
       "4     ./data/gothic_novel_two.txt   \n",
       "5   ./data/gothic_novel_three.txt   \n",
       "6       ./data/cook_book_four.txt   \n",
       "7     ./data/gothic_novel_ten.txt   \n",
       "8   ./data/gothic_novel_eight.txt   \n",
       "9    ./data/gothic_novel_nine.txt   \n",
       "10           ./data/cook_book.txt   \n",
       "11       ./data/cook_book_ten.txt   \n",
       "12      ./data/cook_book_nine.txt   \n",
       "13     ./data/cook_book_eight.txt   \n",
       "14        ./data/gothic_novel.txt   \n",
       "15   ./data/gothic_novel_five.txt   \n",
       "16       ./data/cook_book_six.txt   \n",
       "17       ./data/cook_book_two.txt   \n",
       "18  ./data/gothic_novel_seven.txt   \n",
       "19    ./data/gothic_novel_one.txt   \n",
       "20     ./data/cook_book_seven.txt   \n",
       "21      ./data/cook_book_five.txt   \n",
       "\n",
       "                                                words  \n",
       "0   project gutenberg's the whitehouse cookbook by...  \n",
       "1   the project gutenberg ebook of new royal cook ...  \n",
       "2   the project gutenberg ebook of the works of ed...  \n",
       "3   the project gutenberg ebook of northanger abbe...  \n",
       "4   project gutenberg’s the complete works of will...  \n",
       "5   the project gutenberg ebook of dracula by bram...  \n",
       "6   the project gutenberg ebook of the italian coo...  \n",
       "7   the project gutenberg ebook of the castle of o...  \n",
       "8   the project gutenberg ebook of the vampyre a t...  \n",
       "9   the project gutenberg ebook of the masque of t...  \n",
       "10  the project gutenberg ebook of california mexi...  \n",
       "11  the project gutenberg ebook of seventy five re...  \n",
       "12  the project gutenberg ebook of mrs wilson's co...  \n",
       "13  the project gutenberg ebook of a plain cookery...  \n",
       "14  the project gutenberg ebook of the phantom of ...  \n",
       "15  the project gutenberg ebook of the woman in wh...  \n",
       "16  the project gutenberg ebook of twenty five cen...  \n",
       "17  the project gutenberg ebook old cookery books ...  \n",
       "18  the project gutenberg ebook of frankenstein by...  \n",
       "19  the project gutenberg ebook of the works of ed...  \n",
       "20  the project gutenberg ebook of the belgian coo...  \n",
       "21  project gutenberg's the complete book of chees...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbe3d8-0d74-42a6-a4e1-9b799db6f32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
