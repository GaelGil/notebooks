{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b188161c-acbc-4b0e-b21c-16e5d2209464",
   "metadata": {},
   "source": [
    "# Back Propagations/Neural NetworkNotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa910f74-007a-439e-a24c-d77ff392bd90",
   "metadata": {},
   "source": [
    "Neural networks have a input layer. The input layer is of course the layer that takes in the inputs. We have as many input neurons as we do inputs. For example if we have a dataset of cats and dogs some example inputs would be `ear length`, `fur length`, `weight`, `height`. This would mean we would have a input layer with 4 neurons. These inputs would be in the input layer and would then be passed forward to the next layer. We pass them by getting the sum of the weights times the inputs and adding a bias(sum number). That value is then passed into an activation function. A common function is the sigmoid function so our values will be between 0 and 1. Depening on the value we get from the activation function the neuron will feed forward that information to the next layer or it will not (depends on value). \n",
    "<!-- Each nueron has a bias which is a number between 0 and 1. -->\n",
    "Depending on how many hidden layers we have this would happen again passing from one layer to another. But eventually we would get to the output layer which in this case we have a output layer for 2 neurons. One for dog and one for cat. These would output the probability from 1 to 0 of it being a dog or cat. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77061bfa-e585-47ba-ae8f-167f35790d5d",
   "metadata": {},
   "source": [
    "The math the sum of the weights times the neurosn plus the bias looks like this: Where $w$ is a weight, $n$ is a neuron and $b$ is the bias of the neuron we are moving the data forward to\n",
    "$$ = (w_0*n_0 + w_1*n_1 + w_2*n_2 + w_3*n_3 .... + w_n*n_n + b) $$\n",
    "we can also write this using vectors: \n",
    "# TODO: Seperate the math\n",
    "$$\\vec{w} =\n",
    "\\begin{bmatrix}\n",
    "w_{0,0} & w_{0,1} & w_{0,2} & 0\\\\\n",
    " & .... & & 0  \\\\\n",
    "  &   w_{n,3} & & 0 \n",
    "\\end{bmatrix},\n",
    "\\vec{n}=[n_0, n_1, n_2, n_3 ..... i_n],\n",
    "\\vec{b}=[b_0, b_1, b_2, b_3 ..... b_n]$$\n",
    "$$activation = \\sigma(\\vec{w} * n + b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfd5598-27d2-4415-9c98-2545ea17a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap # for grgphing decision boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da38e9f5-61b6-4255-a0d2-e846df2e6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "X_train = pd.read_csv(f'./{data_folder}/X_train.csv')\n",
    "y_train = pd.read_csv(f'./{data_folder}/y_train.csv')\n",
    "X_test = pd.read_csv(f'./{data_folder}/X_test.csv')\n",
    "y_test = pd.read_csv(f'./{data_folder}/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb133230-6cca-45f3-9661-a96038245748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.5               2.4                3.7               1.0\n",
       "1                  4.8               3.0                1.4               0.1\n",
       "2                  5.5               2.6                4.4               1.2\n",
       "3                  5.0               3.2                1.2               0.2\n",
       "4                  6.9               3.1                5.1               2.3\n",
       "..                 ...               ...                ...               ...\n",
       "107                6.3               2.7                4.9               1.8\n",
       "108                7.2               3.0                5.8               1.6\n",
       "109                5.8               4.0                1.2               0.2\n",
       "110                5.2               3.4                1.4               0.2\n",
       "111                7.2               3.2                6.0               1.8\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1453427-f21c-4424-b311-edc61a32a14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sepal length (cm)    5.5\n",
       " sepal width (cm)     2.4\n",
       " petal length (cm)    3.7\n",
       " petal width (cm)     1.0\n",
       " Name: 0, dtype: float64]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X_train[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']].iloc[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e33661-9370-4c0e-b5f7-072ba9008132",
   "metadata": {},
   "source": [
    "# Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6529eae0-ab0a-4575-8c0d-bf3066532acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of input neurons: 4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the inputs\n",
    "inputs = [X_train.iloc[1]['sepal length (cm)'], X_train.iloc[1]['sepal width (cm)'], X_train.iloc[1]['petal length (cm)'], X_train.iloc[1]['petal length (cm)']]\n",
    "f'Number of input neurons: {len(inputs)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23c8e16-6d0f-4f0d-b401-50052c274e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of neurons at second layer: 4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a second layer\n",
    "second_layer = [random.uniform(0, 1)] * 4\n",
    "f'Number of neurons at second layer: {len(second_layer)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488ccf32-d3a0-4cad-a81c-900efb1b8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weight_matrix(prev_layer, current_layer) -> list:\n",
    "    \"\"\"create a matrix of weights\"\"\"\n",
    "    len_prev_layer, len_current_layer = len(prev_layer), len(current_layer)\n",
    "    matrix_weights = [[random.uniform(0, 1) for x in range(len_prev_layer)] for y in range(len_current_layer)]\n",
    "    return np.array(matrix_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f63c627-fffe-4fc7-944c-8182de43251e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of weights from input layer to second: 16'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The weights connecting the input layer to second layer\n",
    "input_to_second_layer_weights = create_weight_matrix(inputs, second_layer)\n",
    "f'Number of weights from input layer to second: {(input_to_second_layer_weights.size)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5002fc-7379-4dc2-a69b-4b0ce68fe736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of neurons at third layer: 3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a third layer\n",
    "third_layer = [random.uniform(0, 1)] * 3\n",
    "f'Number of neurons at third layer: {len(third_layer)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba9942e-2fc7-4c85-9743-bc2877f07461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of weights from second layer to third: 12'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The weights connecting the second layer to third layer\n",
    "second_to_third_layer_weights = create_weight_matrix(second_layer, third_layer)\n",
    "f'Number of weights from second layer to third: {second_to_third_layer_weights.size}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012e5eb1-ca0f-4803-82b4-0d734d64bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of neurons at output layer: 3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the output values to get number of outpts\n",
    "output_layer_length = len(set((y_train.iloc[:, 0].tolist())))\n",
    "output_layer = [random.uniform(0, 1)] * output_layer_length\n",
    "f'Number of neurons at output layer: {len(output_layer)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e08ee12-858f-4745-807c-07b38ec49b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of weights from third layer to output: 9'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The weights connecting the third layer to output layer\n",
    "third_to_output_layer_weights = create_weight_matrix(third_layer, output_layer)\n",
    "f'Number of weights from third layer to output: {third_to_output_layer_weights.size}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e3788-d191-4faa-9db3-2b162b01e0c4",
   "metadata": {},
   "source": [
    "# Feeding forward the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55d7c3e0-3f29-4a5e-98dd-4687791fc3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(num):\n",
    "    return (1/(1+np.exp(-(num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f794e09-64e8-42fa-bb3a-cefdbf2c673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(weights, layer) -> list:\n",
    "    activations = []\n",
    "    for w in weights:\n",
    "        activation = sigmoid(np.dot(w, layer))\n",
    "        activations.append(activation)\n",
    "        print(activation)\n",
    "        print()\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a365664e-454a-475b-b4eb-b05adfba29c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9898868132928761\n",
      "\n",
      "0.9996447492424151\n",
      "\n",
      "0.9988267740638654\n",
      "\n",
      "0.9560903694202004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_to_second_activations = feed_forward(input_to_second_layer_weights, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bc83517-5167-4dc4-a90b-1ef7ba8bc60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8369375477308798\n",
      "\n",
      "0.932153882421246\n",
      "\n",
      "0.9548756929360769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "second_to_third_layer_activations = feed_forward(second_to_third_layer_weights, input_to_second_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a245110-34ba-4a81-89a2-5b78c345855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310089814686187\n",
      "\n",
      "0.7516274466116787\n",
      "\n",
      "0.7664043795371807\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7310089814686187, 0.7516274466116787, 0.7664043795371807]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_forward(third_to_output_layer_weights, second_to_third_layer_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e93a291-50a1-44eb-9596-27076eeb8316",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30741548-e3ac-433f-996d-25b255c62ba6",
   "metadata": {},
   "source": [
    "This is of course how the neural network works but there is a lot going on and how do we know what are weights and biases are. How is it trained, how do we fix the weight and biases if we have a lot of error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa9f0e-2881-4e9b-b0c7-c2d0fddc51dd",
   "metadata": {},
   "source": [
    "How does the cost function change with respect to weights, bias, activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206560af-37ef-4f23-bce7-bee0988fc777",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=tIeHLnjs5U8&list=PL_h2yd2CGtBHEKwEH5iqTZH85wLS-eUzv&index=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85fcfe-40f7-4e0b-8fe2-fdc946b7a01e",
   "metadata": {},
   "source": [
    "The way to figure this out is using back propagation. Back propagation is a algorithm that helps us figure out how we change the weights and biases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786771c3-5207-49cc-bfb2-aa95dab22231",
   "metadata": {},
   "source": [
    "Similar to linear regression with gradient descent we want to find the the paramaters that will minimize the error in our cost funtion. We of course do this with calculus by taking the gradient of our cost function. Gradient descent will give us the direction in which a function is increasing its fastest. If we take the negative gradient of our function we will get the direction in which the function is decreasing and that is where our error will be minimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8456a6-d374-497e-b90a-1c4dc2e2085f",
   "metadata": {},
   "source": [
    "In our first example we set the weights and biases to some random number. What we now want to do is change our weights and biases to minimize the cost function. \n",
    "\n",
    "For example if we take an example of `iris setosa` as one of the flowers we are trying to classify. We want the output neuron to have a high activation for the output neruon of `iris setosa` by the time the data has been feed forward. We can do this by chaning the weights and by chaning the bias. \n",
    "\n",
    "One thing to keep in mind is changing the size of certain weights can have a better outcome on the output. For example we can have two weights but only one of them will have a signinficant effect on the activation. While changing the other one will little to no effect. \n",
    "\n",
    "Now that we know that if we want a output neuron to have a high activation for an example we can look back at the weights that connect it to the previous layer and change those weights and biases. All these changes made for the example are the way that the example wants to change the weights and biases to get that desired output. We can also do that for the layer before and the layer before that.\n",
    "\n",
    "Of course we have to do this for every example in our dataset that we we are classifying. If we only do that for the `iris setosa`. We will only be able to classify the `iris setosa`. Lastly all the changes for each example in our dataset to each weight and biases are added and average for each training example. All of those changes to the weights and biases are the negative gradient. \n",
    "\n",
    "Now what we want to do is find out by how much to change each weight and bias by. Knowing that we can direclty affect the impact of the output neuron by chaning the weights and biases of the layer connecting them with also that changing certain weights and biases will have a greater affect we can now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3ce26f3-73a9-4d20-b405-1b27524c7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "    def __init__(self, value:float, neuron_type:str):\n",
    "        self.value = value\n",
    "        self.neuron_type = neuron_type\n",
    "        \n",
    "    def set_value(self, value:float):\n",
    "        self.value = value\n",
    "        return 0 \n",
    "    \n",
    "    def get_val(self):\n",
    "        return self.value\n",
    "    \n",
    "    def get_type(self):\n",
    "        return self.neuron_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3b58531-aeb2-415d-8715-9cde14c011be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weights():\n",
    "    def __init__(self, value:float, layer:str):\n",
    "        self.value = value\n",
    "        self.layer = layer\n",
    "    def set_val(self, value:float):\n",
    "        self.value = value\n",
    "        return self.value\n",
    "    def get_val(self):\n",
    "        return self.value\n",
    "    def get_layer(self):\n",
    "        return self.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c8f3650-3cb3-4b32-94e7-f4fb3ef5d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, inputs):\n",
    "        self.__input_layer = self.initialize_input_layer(inputs)\n",
    "#         self.output_layer = self.initialize_output_layer(outputs)\n",
    "        self.__weights = []\n",
    "        self.__layers = []\n",
    "\n",
    "    @classmethod\n",
    "    def initialize_input_layer(self, inputs:list, neuron_type='input'):\n",
    "        \"\"\" function to give a neuron a activation value \"\"\"\n",
    "        input_layer = []\n",
    "        for i in inputs:\n",
    "#             neuron = self.create_neuron(i, neuron_type)\n",
    "            input_layer.append(i)\n",
    "        return input_layer\n",
    "\n",
    "    @classmethod\n",
    "    def create_neuron(self, value:float, neuron_type:str):\n",
    "        \"\"\" function to create a nueron \"\"\"\n",
    "        neuron = Neuron(value, neuron_type)\n",
    "        return neuron\n",
    "    \n",
    "    def get_network_info(self):\n",
    "        \"\"\" function to get number of layers, weights, neurons\"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def get_input_layer(self):\n",
    "        \"\"\" function to get the input layer \"\"\"\n",
    "        return self.__input_layer\n",
    "    \n",
    "    def get_layer(self, num_layer:int):\n",
    "        \"\"\" function to get a single layer (not input our output) \"\"\"\n",
    "        return self.__layers[num_layer]\n",
    "    \n",
    "    def get_weights(self, num_weights:int):\n",
    "        return self.__weights[num_weights]\n",
    "    \n",
    "    def create_hidden_layers(self, num_layers:int, neurons_in_layer:list):\n",
    "        \"\"\" function to create hidden layers \"\"\"\n",
    "        # for num of layers\n",
    "        for i in range(num_layers):\n",
    "            # create a empty list for neurons\n",
    "            current_layer = []\n",
    "            # create a neurons\n",
    "            for j in range(neurons_in_layer[i]):\n",
    "                neuron = self.create_neuron(0.0 ,f'hidden layer #{i+1}' )\n",
    "                current_layer.append(neuron)\n",
    "            # add list of neurons to list of layers\n",
    "            self.__layers.append(current_layer)\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def create_weights(self):\n",
    "        input_layer = len(self.get_input_layer())\n",
    "        layer_after_input = len(self.get_layer(0))\n",
    "        self.__weights.append(np.random.rand(input_layer,layer_after_input)) \n",
    "        return 0 \n",
    "            \n",
    "    def sigmoid(self, activation):\n",
    "        return (1/(1+np.exp(-(activation))))\n",
    "    \n",
    "    def feed_forward(self):\n",
    "        \"\"\" feed the neural network forward \"\"\"\n",
    "        activations = self.sigmoid(np.dot(self.get_input_layer(), self.get_weights(0)))\n",
    "        print(activations)   \n",
    "        return 0\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3066033f-3afb-4759-927d-15f264c87661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.8, 3.0, 1.4, 1.4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [X_train.iloc[1]['sepal length (cm)'], X_train.iloc[1]['sepal width (cm)'], X_train.iloc[1]['petal length (cm)'], X_train.iloc[1]['petal length (cm)']]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16478eaf-bbbe-49d5-b03c-d36bc92c17fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.8, 3.0, 1.4, 1.4]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork(example)\n",
    "nn.get_input_layer()\n",
    "# for i in nn.get_input_layer():\n",
    "#     print(i.get_val())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33e3ef6d-25bd-4a6a-948c-9a36453499a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.create_hidden_layers(2, [4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "880d86aa-28b2-466f-9bf9-90d9c121f245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9408361 , 0.56595892, 0.49524091, 0.62710385],\n",
       "       [0.22182629, 0.64182771, 0.18211054, 0.80650639],\n",
       "       [0.46538852, 0.85910511, 0.99648061, 0.58690026],\n",
       "       [0.70340648, 0.75860542, 0.12153556, 0.92151061]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.create_weights()\n",
    "nn.get_weights(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfd1f4da-aa44-4c8c-abf4-f5393f7ed143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99890708 0.99900013 0.9888897  0.99946962]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.feed_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cd5d9-2143-4c11-8ae5-d00807848f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
