{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b188161c-acbc-4b0e-b21c-16e5d2209464",
   "metadata": {},
   "source": [
    "# Back Propagations/Neural NetworkNotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa910f74-007a-439e-a24c-d77ff392bd90",
   "metadata": {},
   "source": [
    "Neural networks have a input layer. The input layer is of course the layer that takes in the inputs. We have as many input neurons as we do inputs. For example if we have a dataset of cats and dogs some example inputs would be `ear length`, `fur length`, `weight`, `height`. This would mean we would have a input layer with 4 neurons. These inputs would be in the input layer and would then be passed forward to the next layer. We pass them by getting the sum of the weights times the inputs and adding a bias(sum number). That value is then passed into an activation function. A common function is the sigmoid function so our values will be between 0 and 1. Depening on the value we get from the activation function the neuron will feed forward that information to the next layer or it will not (depends on value). \n",
    "<!-- Each nueron has a bias which is a number between 0 and 1. -->\n",
    "Depending on how many hidden layers we have this would happen again passing from one layer to another. But eventually we would get to the output layer which in this case we have a output layer for 2 neurons. One for dog and one for cat. These would output the probability from 1 to 0 of it being a dog or cat. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77061bfa-e585-47ba-ae8f-167f35790d5d",
   "metadata": {},
   "source": [
    "The math the sum of the weights times the neurosn plus the bias looks like this: Where $w$ is a weight, $n$ is a neuron and $b$ is the bias of the neuron we are moving the data forward to\n",
    "$$ = (w_0*n_0 + w_1*n_1 + w_2*n_2 + w_3*n_3 .... + w_n*n_n + b) $$\n",
    "we can also write this using vectors: \n",
    "# TODO: Seperate the math\n",
    "$$\\vec{w} =\n",
    "\\begin{bmatrix}\n",
    "w_{0,0} & w_{0,1} & w_{0,2} & 0\\\\\n",
    " & .... & & 0  \\\\\n",
    "  &   w_{n,3} & & 0 \n",
    "\\end{bmatrix},\n",
    "\\vec{n}=[n_0, n_1, n_2, n_3 ..... i_n],\n",
    "\\vec{b}=[b_0, b_1, b_2, b_3 ..... b_n]$$\n",
    "$$activation = \\sigma(\\vec{w} * n + b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfd5598-27d2-4415-9c98-2545ea17a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap # for grgphing decision boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da38e9f5-61b6-4255-a0d2-e846df2e6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "X_train = pd.read_csv(f'./{data_folder}/X_train.csv')\n",
    "y_train = pd.read_csv(f'./{data_folder}/y_train.csv')\n",
    "X_test = pd.read_csv(f'./{data_folder}/X_test.csv')\n",
    "y_test = pd.read_csv(f'./{data_folder}/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb133230-6cca-45f3-9661-a96038245748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.5               2.4                3.7               1.0\n",
       "1                  4.8               3.0                1.4               0.1\n",
       "2                  5.5               2.6                4.4               1.2\n",
       "3                  5.0               3.2                1.2               0.2\n",
       "4                  6.9               3.1                5.1               2.3\n",
       "..                 ...               ...                ...               ...\n",
       "107                6.3               2.7                4.9               1.8\n",
       "108                7.2               3.0                5.8               1.6\n",
       "109                5.8               4.0                1.2               0.2\n",
       "110                5.2               3.4                1.4               0.2\n",
       "111                7.2               3.2                6.0               1.8\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1453427-f21c-4424-b311-edc61a32a14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sepal length (cm)    5.5\n",
       " sepal width (cm)     2.4\n",
       " petal length (cm)    3.7\n",
       " petal width (cm)     1.0\n",
       " Name: 0, dtype: float64]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X_train[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']].iloc[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e33661-9370-4c0e-b5f7-072ba9008132",
   "metadata": {},
   "source": [
    "# Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6529eae0-ab0a-4575-8c0d-bf3066532acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of input neurons: 4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the inputs\n",
    "inputs = [X_train.iloc[1]['sepal length (cm)'], X_train.iloc[1]['sepal width (cm)'], X_train.iloc[1]['petal length (cm)'], X_train.iloc[1]['petal length (cm)']]\n",
    "f'Number of input neurons: {len(inputs)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a23c8e16-6d0f-4f0d-b401-50052c274e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of neurons at second layer: 4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a second layer\n",
    "second_layer = [random.uniform(0, 1)] * 4\n",
    "f'Number of neurons at second layer: {len(second_layer)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488ccf32-d3a0-4cad-a81c-900efb1b8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weight_matrix(prev_layer, current_layer) -> list:\n",
    "    \"\"\"create a matrix of weights\"\"\"\n",
    "    len_prev_layer, len_current_layer = len(prev_layer), len(current_layer)\n",
    "    matrix_weights = [[random.uniform(0, 1) for x in range(len_prev_layer)] for y in range(len_current_layer)]\n",
    "    return np.array(matrix_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f63c627-fffe-4fc7-944c-8182de43251e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of weights from input layer to second: 16'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The weights connecting the input layer to second layer\n",
    "input_to_second_layer_weights = create_weight_matrix(inputs, second_layer)\n",
    "f'Number of weights from input layer to second: {(input_to_second_layer_weights.size)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5002fc-7379-4dc2-a69b-4b0ce68fe736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of neurons at third layer: 3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a third layer\n",
    "third_layer = [random.uniform(0, 1)] * 3\n",
    "f'Number of neurons at third layer: {len(third_layer)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba9942e-2fc7-4c85-9743-bc2877f07461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of weights from second layer to third: 12'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The weights connecting the second layer to third layer\n",
    "second_to_third_layer_weights = create_weight_matrix(second_layer, third_layer)\n",
    "f'Number of weights from second layer to third: {second_to_third_layer_weights.size}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012e5eb1-ca0f-4803-82b4-0d734d64bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of neurons at output layer: 3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the output values to get number of outpts\n",
    "output_layer_length = len(set((y_train.iloc[:, 0].tolist())))\n",
    "output_layer = [random.uniform(0, 1)] * output_layer_length\n",
    "f'Number of neurons at output layer: {len(output_layer)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e08ee12-858f-4745-807c-07b38ec49b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of weights from third layer to output: 9'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The weights connecting the third layer to output layer\n",
    "third_to_output_layer_weights = create_weight_matrix(third_layer, output_layer)\n",
    "f'Number of weights from third layer to output: {third_to_output_layer_weights.size}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e3788-d191-4faa-9db3-2b162b01e0c4",
   "metadata": {},
   "source": [
    "# Feeding forward the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55d7c3e0-3f29-4a5e-98dd-4687791fc3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(num):\n",
    "    return (1/(1+np.exp(-(num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f794e09-64e8-42fa-bb3a-cefdbf2c673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(weights, layer) -> list:\n",
    "    activations = []\n",
    "    for w in weights:\n",
    "        activation = sigmoid(np.dot(w, layer))\n",
    "        activations.append(activation)\n",
    "        print(activation)\n",
    "        print()\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a365664e-454a-475b-b4eb-b05adfba29c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997468190219861\n",
      "\n",
      "0.9984373971531718\n",
      "\n",
      "0.9521088299663936\n",
      "\n",
      "0.9955099760013053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_to_second_activations = feed_forward(input_to_second_layer_weights, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bc83517-5167-4dc4-a90b-1ef7ba8bc60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7652229881119174\n",
      "\n",
      "0.8459972723071569\n",
      "\n",
      "0.8035680228908066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "second_to_third_layer_activations = feed_forward(second_to_third_layer_weights, input_to_second_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a245110-34ba-4a81-89a2-5b78c345855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7399904950710097\n",
      "\n",
      "0.7907503747433197\n",
      "\n",
      "0.7422785462576861\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7399904950710097, 0.7907503747433197, 0.7422785462576861]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_forward(third_to_output_layer_weights, second_to_third_layer_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e93a291-50a1-44eb-9596-27076eeb8316",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30741548-e3ac-433f-996d-25b255c62ba6",
   "metadata": {},
   "source": [
    "This is of course how the neural network works but there is a lot going on and how do we know what are weights and biases are. How is it trained, how do we fix the weight and biases if we have a lot of error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa9f0e-2881-4e9b-b0c7-c2d0fddc51dd",
   "metadata": {},
   "source": [
    "How does the cost function change with respect to weights, bias, activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206560af-37ef-4f23-bce7-bee0988fc777",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=tIeHLnjs5U8&list=PL_h2yd2CGtBHEKwEH5iqTZH85wLS-eUzv&index=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85fcfe-40f7-4e0b-8fe2-fdc946b7a01e",
   "metadata": {},
   "source": [
    "The way to figure this out is using back propagation. Back propagation is a algorithm that helps us figure out how we change the weights and biases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786771c3-5207-49cc-bfb2-aa95dab22231",
   "metadata": {},
   "source": [
    "Similar to linear regression with gradient descent we want to find the the paramaters that will minimize the error in our cost funtion. We of course do this with calculus by taking the gradient of our cost function. Gradient descent will give us the direction in which a function is increasing its fastest. If we take the negative gradient of our function we will get the direction in which the function is decreasing and that is where our error will be minimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8456a6-d374-497e-b90a-1c4dc2e2085f",
   "metadata": {},
   "source": [
    "In our first example we set the weights and biases to some random number. What we now want to do is change our weights and biases to minimize the cost function. \n",
    "\n",
    "For example if we take an example of `iris setosa` as one of the flowers we are trying to classify. We want the output neuron to have a high activation for the output neruon of `iris setosa` by the time the data has been feed forward. We can do this by chaning the weights and by chaning the bias. \n",
    "\n",
    "One thing to keep in mind is changing the size of certain weights can have a better outcome on the output. For example we can have two weights but only one of them will have a signinficant effect on the activation. While changing the other one will little to no effect. \n",
    "\n",
    "Now that we know that if we want a output neuron to have a high activation for an example we can look back at the weights that connect it to the previous layer and change those weights and biases. All these changes made for the example are the way that the example wants to change the weights and biases to get that desired output. We can also do that for the layer before and the layer before that.\n",
    "\n",
    "Of course we have to do this for every example in our dataset that we we are classifying. If we only do that for the `iris setosa`. We will only be able to classify the `iris setosa`. Lastly all the changes for each example in our dataset to each weight and biases are added and average for each training example. All of those changes to the weights and biases are the negative gradient. \n",
    "\n",
    "Now what we want to do is find out by how much to change each weight and bias by. Knowing that we can direclty affect the impact of the output neuron by chaning the weights and biases of the layer connecting them with also that changing certain weights and biases will have a greater affect we can now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c8f3650-3cb3-4b32-94e7-f4fb3ef5d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeuralNetwork:\n",
    "#     def __init__(self, X, y):\n",
    "#         self.__input_layer, self.__output_layer = self.initialize_input_output_layer(X, y)\n",
    "#         self.__y = y\n",
    "#         self.__weights = []\n",
    "#         self.__layers = []\n",
    "#         self.__biases = []\n",
    "\n",
    "#     @classmethod\n",
    "#     def initialize_input_output_layer(self, X:list, y,neuron_type='input'):\n",
    "#         \"\"\" function to give a neuron a activation value \"\"\"\n",
    "#         input_layer = [i for i in X]\n",
    "#         output_layer = [0] * 3\n",
    "#         if y == 'Iris-setosa':\n",
    "#             output_layer[0] = 1\n",
    "#         elif y == 'Iris-versicolor':\n",
    "#             output_layer[1] = 1\n",
    "#         else: \n",
    "#             output_layer[2] = 1\n",
    "#         return input_layer, output_layer\n",
    "    \n",
    "#     def get_input_layer(self):\n",
    "#         \"\"\" function to get the input layer \"\"\"\n",
    "#         return self.__input_layer\n",
    "\n",
    "#     def get_output_layer(self):\n",
    "#         \"\"\" function to get the input layer \"\"\"\n",
    "#         return self.__output_layer\n",
    "    \n",
    "#     def get_weights(self, num_weights:int):\n",
    "#         return self.__weights[num_weights]\n",
    "    \n",
    "#     def set_layers(self, new_layers):\n",
    "#         self.__layers = new_layers.copy()\n",
    "\n",
    "#     def merge_layers(self):\n",
    "#         \"\"\"function to merge layers into one list\"\"\"\n",
    "#         all_layers = []\n",
    "#         layers = self.__layers\n",
    "#         input_layer = self.get_input_layer()\n",
    "#         output_layer = self.get_output_layer()\n",
    "#         all_layers.append(input_layer)\n",
    "#         all_layers.extend(layers)\n",
    "#         all_layers.append(output_layer)\n",
    "#         return all_layers\n",
    "\n",
    "#     def create_biases(self):\n",
    "#         \"\"\" create biases \"\"\"\n",
    "#         # create a list of biases for each layer except output\n",
    "#         self.__biases = [[0] for i in range(len(self.__layers)-1)]\n",
    "#         return 0\n",
    "    \n",
    "#     def create_hidden_layers(self, num_layers:int, neurons_in_layer:list):\n",
    "#         \"\"\" function to create hidden layers \"\"\"\n",
    "#         # for num of layers\n",
    "#         for i in range(num_layers):\n",
    "#             # create a empty list for neurons\n",
    "#             current_layer = []\n",
    "#             # create a neurons\n",
    "#             for j in range(neurons_in_layer[i]):\n",
    "#                 # neuron = self.create_neuron(0.0 ,f'hidden layer #{i+1}' )\n",
    "#                 current_layer.append(0.0)\n",
    "#             # add list of neurons to list of layers\n",
    "#             self.__layers.append(current_layer)\n",
    "#         # create the weights now that we have layers\n",
    "#         self.create_weights()\n",
    "#         return 0\n",
    " \n",
    "\n",
    "#     def create_weights(self):\n",
    "#         # merge all the layers into one big list\n",
    "#         layers = self.merge_layers()\n",
    "#         # set the merged layers to the class layers\n",
    "#         self.set_layers(layers)\n",
    "#         # create the biases for the layers\n",
    "#         self.create_biases()\n",
    "#         # create weights (matrix) connecting the layers to each other\n",
    "#         # for every layer\n",
    "#         for layer in range(len(layers)-1):\n",
    "#             # get the length of the current layer\n",
    "#             current_layer = len(layers[layer])\n",
    "#             # get the length of the next layer\n",
    "#             next_layer = len(layers[layer+1])\n",
    "#             # create a matrix and append to list using the lengths of the layers \n",
    "#             self.__weights.append(np.random.rand(current_layer,next_layer))\n",
    "        \n",
    "#         return 0 \n",
    "\n",
    "    \n",
    "#     def sigmoid(self, activation):\n",
    "#         return (1/(1+np.exp(-(activation)))) \n",
    "\n",
    "#     def feed_forward(self):\n",
    "#         \"\"\" feed the neural network forward \"\"\"\n",
    "#         layers = self.__layers\n",
    "#         for i in range(len(layers)-1):\n",
    "#             # calculate the activations\n",
    "#             activations = self.sigmoid(np.dot(layers[i], self.get_weights(i)) + self.__biases[i])\n",
    "#             # pass the activations to the next layer\n",
    "#             layers[i+1] = activations.copy()\n",
    "#         return layers[-1]\n",
    "\n",
    "#     def back_propogation(self):\n",
    "#         predicted = self.feed_forward()\n",
    "#         layers = self.__layers # layer before output\n",
    "#         layer = layers[-2]\n",
    "#         print(layer)\n",
    "#         print(self.__y)\n",
    "#         cost_function_derivative = 2*(layer-self.__y)\n",
    "#         print(cost_function_derivative)\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c82e135b-f2bf-42bc-843f-88530d991df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.8, 3.0, 1.4, 1.4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = [X_train.iloc[1]['sepal length (cm)'], X_train.iloc[1]['sepal width (cm)'], X_train.iloc[1]['petal length (cm)'], X_train.iloc[1]['petal length (cm)']]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e691c88-25d9-4cc4-a75e-abda5fd6e4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-setosa'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = y_train.iloc[1]['class']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16478eaf-bbbe-49d5-b03c-d36bc92c17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn = NeuralNetwork(example, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33e3ef6d-25bd-4a6a-948c-9a36453499a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nn.create_hidden_layers(2, [4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfd1f4da-aa44-4c8c-abf4-f5393f7ed143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.back_propogation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "973cd5d9-2143-4c11-8ae5-d00807848f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, sample_input, num_layers, neurons_per_layer):\n",
    "        self.layers = self.create_layers(sample_input, num_layers, neurons_per_layer)\n",
    "        self.weights = self.create_weights()\n",
    "        self.biases = [[0] for i in range(num_layers+1)]\n",
    "        \n",
    "    @classmethod\n",
    "    def create_layers(self, sample_input, num_layers, neurons_per_layer):\n",
    "        \"\"\" function to create hidden layers \"\"\"\n",
    "        input_layer = [i for i in sample_input]\n",
    "        output_layer = [0 for i in range(3)]\n",
    "        layers = []\n",
    "        layers.append(input_layer)\n",
    "        # for num of layers\n",
    "        for i in range(num_layers):\n",
    "            # create a empty list for neurons\n",
    "            current_layer = []\n",
    "            # create a neurons\n",
    "            for j in range(neurons_per_layer[i]):\n",
    "                # neuron = self.create_neuron(0.0 ,f'hidden layer #{i+1}' )\n",
    "                current_layer.append(0.0)\n",
    "            # add list of neurons to list of layers\n",
    "            layers.append(current_layer)\n",
    "        layers.append(output_layer)\n",
    "        print(layers)\n",
    "        return layers\n",
    "\n",
    "    def create_weights(self):\n",
    "        weights = []\n",
    "        layers = self.layers\n",
    "        for i in range(len(layers)-1):\n",
    "            # get the length of the current layer\n",
    "            current_layer = len(layers[i])\n",
    "            # get the length of the next layer\n",
    "            next_layer = len(layers[i+1])\n",
    "            # create a matrix and append to list using the lengths of the layers \n",
    "            weights.append(np.random.rand(current_layer,next_layer))\n",
    "        return weights \n",
    "        \n",
    "        \n",
    "    def sigmoid(self, activation):\n",
    "        return (1/(1+np.exp(-(activation))))\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        layers = self.layers\n",
    "        for i in range(len(layers)-1):\n",
    "            activations = self.sigmoid(np.dot(layers[i], self.weights[i]) + self.biases[i])\n",
    "            # pass the activations to the next layer\n",
    "            layers[i+1] = activations.copy()\n",
    "        return (layers[-1], max(layers[-1]))\n",
    "\n",
    "    def back_propagation(self, output, y):\n",
    "        layers = self.layers\n",
    "        print(layers)\n",
    "        print()\n",
    "        for i in range((len(layers)), 0,-1):\n",
    "            cost_function_derivative = 2*(output - y)\n",
    "            print(i-1)\n",
    "            sigmoid_derivative = cost_function_derivative * (-(np.exp(-(output))))/((1+np.exp(-(output))) ** 2)\n",
    "            prev_layer = layers[i-1]\n",
    "            print(prev_layer)\n",
    "            print()\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d1cdfa9-bd62-4530-b919-1ce91683585f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.8, 3.0, 1.4, 1.4], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "new_class = Network(example,2, [4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81afd0d2-c1b0-4885-a7ce-946af0545aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [X_train.iloc[1]['sepal length (cm)'], X_train.iloc[1]['sepal width (cm)'], X_train.iloc[1]['petal length (cm)'], X_train.iloc[1]['petal length (cm)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cda4c06e-860c-44a9-9e18-80da8eb0df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer, predicted = new_class.feed_forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63738b9c-3127-4612-817c-e9f1682b3fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-setosa'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_train.iloc[1]['class']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d06e7585-5331-4459-94ef-3c01d2b272c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.8, 3.0, 1.4, 1.4], array([0.99436741, 0.99754766, 0.99790173, 0.99129996]), array([0.80639164, 0.72572826, 0.8432921 ]), array([0.84828101, 0.84991827, 0.70959594])]\n",
      "\n",
      "5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c6/fdtwnncn1vn0kw0f_jd84mcm0000gp/T/ipykernel_1606/379008992.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/c6/fdtwnncn1vn0kw0f_jd84mcm0000gp/T/ipykernel_1606/1239212965.py\u001b[0m in \u001b[0;36mback_propagation\u001b[0;34m(self, output, y)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0msigmoid_derivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_function_derivative\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mprev_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "new_class.back_propagation(predicted, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd64601-9b00-478f-9944-8ac14943e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feed_forward_and_back_propogate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
