{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dbb0df6-264e-4f31-8d4c-50dbb1cbbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap # for grgphing decision boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b89188-8ee5-45a7-b82e-1e8ffbcf16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "X_train = pd.read_csv(f'./{data_folder}/X_train.csv')\n",
    "y_train = pd.read_csv(f'./{data_folder}/y_train.csv')\n",
    "X_test = pd.read_csv(f'./{data_folder}/X_test.csv')\n",
    "y_test = pd.read_csv(f'./{data_folder}/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3f4671-84b2-44e5-ad53-b067585858a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        # layers/activations\n",
    "        self.input = np.random.rand(4, 1)\n",
    "        self.h1 = np.random.rand(2, 1)\n",
    "        self.h2 = np.random.rand(3, 1)\n",
    "        \n",
    "        # weights \n",
    "        self.w_1 = np.random.rand(2, 4)\n",
    "        self.w_2 = np.random.rand(3, 2)\n",
    "        \n",
    "        # biases \n",
    "        self.b_1 = np.random.rand(2, 1)\n",
    "        self.b_2 = np.random.rand(3, 1)\n",
    "\n",
    "        \n",
    "    def one_hot(self,y):\n",
    "        one_hot_y = np.zeros((y.size, y.max()+1))\n",
    "        one_hot_y[np.range(y,size), y] = 1\n",
    "        return one_hot_y.T\n",
    "\n",
    "    def relu(self,activations):\n",
    "        return np.maximum(0, activations)\n",
    "\n",
    "    def relu_deriv(self, activations):\n",
    "        return activations > 0\n",
    "\n",
    "    def softmax(self, activations):\n",
    "        return np.exp(activations) / np.sum(np.exp(activations))\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        # input\n",
    "        # reshapre the input into vector form.\n",
    "        # Example [1, 0, 0] -> [[1], [1], [1]]\n",
    "        self.input = np.reshape(X, (-1,1))\n",
    "        \n",
    "        # input -> h1\n",
    "        # the activations in the first hidden layer are given by the dot product \n",
    "        # of the weights by the input plus some biass its all then passed into\n",
    "        # our activation function. relu(W_1*x+b_1)\n",
    "        h1_activations = self.relu(np.dot(self.w_1, self.input) + self.b_1)\n",
    "        self.h1 = h1_activations\n",
    "\n",
    "        # h1 -> h2\n",
    "        # the activations in the seocnd hidden layer (h_2) are given by the dot product \n",
    "        # of the second weights (w_2) by the previous activations (h1) plus the bias(b_2).\n",
    "        # W_2*h1+b_2\n",
    "        h2_activations = (np.dot(self.w_2, h1_activations) + self.b_2)\n",
    "        self.h2 = h2_activations \n",
    "\n",
    "        # h2 -> output \n",
    "        # our output activtions/predictions are given by the second layer activations (h_2)\n",
    "        # put into the softmax function. \n",
    "        output = self.softmax(self.h2)\n",
    "        \n",
    "        return (output, max(output))\n",
    "    \n",
    "    def back_prop(self, output, y, learning_rate=0.01):\n",
    "        y = np.reshape(y, (-1,1))\n",
    "#         print(input_)\n",
    "        \n",
    "        # Derivative of the cost function.\n",
    "        # The cost function is C = (output - y)^2\n",
    "        # The derivative of that is 2 (output - y)\n",
    "        dc = (2 * (output - y))\n",
    "        \n",
    "        # Derivative of the cost function with respect to the weights (w_2).\n",
    "        # The because our output is given by: output = w_2*h_1+b_2. The deriative\n",
    "        # of the cost function with respect to w_2 is: dc * h1\n",
    "        dc_dw2 = -learning_rate * dc.dot(self.h1.T)\n",
    "        b_2 = -learning_rate * dc\n",
    "\n",
    "\n",
    "        # Derivative of the cost function with respect to the first weights (w_1)\n",
    "        # h1 is given by w_1*x+b_1\n",
    "        h1_error = self.w_2.T.dot(dc) * self.relu_deriv(self.h1)\n",
    "        dc_dw1 = -learning_rate * (h1_error.dot(self.input.T))\n",
    "        b_1 = -learning_rate * h1_error\n",
    "        \n",
    "        self.w_1 +=  dc_dw1\n",
    "        self.w_2 +=  dc_dw2\n",
    "        \n",
    "        self.b_1 += b_1\n",
    "        self.b_2 += b_2\n",
    "        return 0\n",
    "       \n",
    "    def get_accuracy(self, data):\n",
    "        total = 0 \n",
    "        for index, row in data.iterrows():\n",
    "            # select the label\n",
    "            y = row.tolist()[4:]\n",
    "            # select the x\n",
    "            X = row.tolist()[:4] \n",
    "            output, predicted = self.feed_forward(X)\n",
    "            label_index = y.index(max(y))\n",
    "            predicted_index = np.where(output==predicted)[0][0]\n",
    "            if label_index == predicted_index:\n",
    "                total += 1\n",
    "        return total/data.shape[0]\n",
    "        \n",
    "\n",
    "    def train(self, X, Y, itterations):        \n",
    "        y_dummies = pd.get_dummies(Y)\n",
    "        data = pd.concat([X, y_dummies], axis=1)\n",
    "        for i in range(itterations):\n",
    "            for index, row in data.iterrows():\n",
    "                # select the label\n",
    "                y = row.tolist()[4:]\n",
    "                # select the x\n",
    "                x = row.tolist()[:4] \n",
    "                output_activations, prediction = self.feed_forward(x)\n",
    "                self.back_prop(output_activations, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90eb6e7c-be61-4b80-8ea6-ef03f98a5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X_test, pd.get_dummies(y_test)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d98d4d-1212-4c11-ba66-b75480abcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_class = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30effb8b-e8ee-473a-85c3-5f40a69a73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_class.train(X_train, y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcfb107-454d-4214-bfdd-d1607d21e91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.2, 2.8, 4.8, 1.8]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.iloc[0].to_list()[:4]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d98ef19-f283-4a53-9b8f-3cc32abec4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.iloc[0].to_list()[4:]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35674a08-a868-4480-a264-28469474399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.32233102e-10],\n",
       "        [6.34936913e-02],\n",
       "        [9.36506309e-01]]),\n",
       " array([0.93650631]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_class.feed_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992bdbbb-1015-41c2-8d54-44b18ea6ff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_class.get_accuracy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca859202-27d0-492f-80d3-86598ac6192e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b83a3d-1056-47a4-82e1-4737ea96bfea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
