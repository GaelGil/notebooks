{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dbb0df6-264e-4f31-8d4c-50dbb1cbbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap # for grgphing decision boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b89188-8ee5-45a7-b82e-1e8ffbcf16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "X_train = pd.read_csv(f'./{data_folder}/X_train.csv')\n",
    "y_train = pd.read_csv(f'./{data_folder}/y_train.csv')\n",
    "X_test = pd.read_csv(f'./{data_folder}/X_test.csv')\n",
    "y_test = pd.read_csv(f'./{data_folder}/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3f4671-84b2-44e5-ad53-b067585858a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers):\n",
    "        self.layers, self.weights, self.biases = self.create_weights_biases_layers(layers)\n",
    "        # layers/activations\n",
    "        self.input = np.random.rand(4, 1)\n",
    "        self.h1 = np.random.rand(4, 1)\n",
    "        self.h2 = np.random.rand(3, 1)\n",
    "        self.output = np.random.rand(3, 1)\n",
    "        \n",
    "        # weights \n",
    "        self.weights_input_h1 = np.random.rand(4, 4)\n",
    "        self.weights_h1_h2 = np.random.rand(3, 4)\n",
    "        self.weights_h2_output = np.random.rand(3, 3)\n",
    "        \n",
    "        # biases = \n",
    "        self.biases_input_h1 = np.random.rand(4, 1)\n",
    "        self.biases_h1_h2 = np.random.rand(3, 1)\n",
    "        self.biases_h2_output = np.random.rand(3, 1)\n",
    "        \n",
    "    @classmethod\n",
    "    def create_weights_biases_layers(self, layers):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        layers_vectors = [0] * len(layers)\n",
    "        for i in range(len(layers)-1):\n",
    "            weights.append(np.random.randn(layers[i+1], layers[i]))\n",
    "            biases.append(np.random.randn(layers[i+1], 1))\n",
    "            \n",
    "            current_layer = [[0] for j in  range(layers[i])]\n",
    "            layers_vectors[i+1] = np.reshape(current_layer, (-1,1))\n",
    "        \n",
    "        return layers_vectors, weights, biases\n",
    "            \n",
    "    def sigmoid(self, activation):\n",
    "        return (1/(1+np.exp(-(activation))))\n",
    "\n",
    "    def feed_forward(self, X):\n",
    "        # select the layers\n",
    "\n",
    "        # input\n",
    "        self.input = np.reshape(X, (-1,1))\n",
    "\n",
    "        # input to h1\n",
    "        h1_activations = self.sigmoid(np.dot(self.weights_input_h1, self.input) + self.biases_input_h1)\n",
    "        self.h1 = h1_activations\n",
    "\n",
    "        # h1 to h2\n",
    "        h2_activations = self.sigmoid(np.dot(self.weights_h1_h2, h1_activations) + self.biases_h1_h2)\n",
    "        self.h2 = h2_activations\n",
    "\n",
    "        # h2 to output \n",
    "        output_activations = np.dot(self.weights_h2_output, h2_activations) + self.biases_h2_output\n",
    "        self.output =  np.exp(output_activations ) / sum(np.exp(output_activations))\n",
    "        \n",
    "        print(output_activations)\n",
    "        print(self.output)\n",
    "        return (self.output, max(self.output))\n",
    "    \n",
    "    def back_prop(self, output, y, learning_rate=0.01):\n",
    "        weights = self.weights\n",
    "        biases = self.biases\n",
    "        layers = self.layers\n",
    "        \n",
    "        new_weights = weights.copy()\n",
    "        new_biases = biases.copy()\n",
    "        \n",
    "        cost_function_derivative = 2 * (output - y)\n",
    "        # output to h2         \n",
    "        dc_dw_output_h2 = layers[2].T * cost_function_derivative\n",
    "        new_weights[2] += (-learning_rate * dc_dw_output_h2)\n",
    "        \n",
    "        dc_db = cost_function_derivative\n",
    "        \n",
    "        # h2 to h1\n",
    "        z_1 = np.dot(dc_dw_output_h2.T, cost_function_derivative) * (self.sigmoid(layers[2])*self.sigmoid(layers[2]))\n",
    "        new_weights[1] += (-learning_rate * (z_1 * layers[1].T))\n",
    "    \n",
    "        \n",
    "        # h1 to input\n",
    "        z_2 = np.dot(new_weights[1].T, cost_function_derivative) * (self.sigmoid(layers[1])*self.sigmoid(layers[1]))\n",
    "        new_weights[0] += (-learning_rate * (z_2 * layers[0].T))\n",
    "\n",
    "        # cost function derivative\n",
    "        cost_function_derivative = 2 (output - y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return new_weights, new_biases\n",
    "       \n",
    "    def update_weights_biases(self, weights, biases):\n",
    "        return 0\n",
    "\n",
    "    def train(self, X, y):\n",
    "        y_dummies = pd.get_dummies(y)\n",
    "        data = pd.concat([X, y_dummies], axis=1)\n",
    "        for index, row in data.iterrows():\n",
    "            y = np.reshape(row.tolist()[4:], (-1,1))\n",
    "            x = row.tolist()[:4]\n",
    "            output_activations, prediction = self.feed_forward(x)\n",
    "            new_weights, new_biases = self.back_prop(output_activations, y)\n",
    "            \n",
    "#         self.update_weights_biases()\n",
    "        return 0\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc31842-9c14-434b-87d4-2e52ee716518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.5, 2.4, 3.7, 1.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90eb6e7c-be61-4b80-8ea6-ef03f98a5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons at each layers input, h1, h2, output\n",
    "layers = (len(X_train.iloc[0]), 4, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d98d4d-1212-4c11-ba66-b75480abcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_class = Network(layers=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10371dc4-bc02-4134-a1b6-5650df85888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.14169016]\n",
      " [1.265661  ]\n",
      " [1.16570876]]\n",
      "[[0.55764499]\n",
      " [0.2322219 ]\n",
      " [0.2101331 ]]\n"
     ]
    }
   ],
   "source": [
    "outputs, output = new_class.feed_forward(np.reshape(list(X_train.iloc[0]), [-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da158637-5b46-4d0e-8c90-9b96c4ea6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_class.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b252e73-1706-476b-aa30-d24abb78d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_class.predict(list(X_test.iloc[0]), np.reshape(list(pd.get_dummies(y_test).iloc[0]), [-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f14e3ec-0cb5-4031-9e69-f2ab3c587da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_class.get_accuracy(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71b2c262-91d3-43a8-b1ac-72fea22e18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_class.get_accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbdd84b6-eea0-404f-adb1-2cf66002a2a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3) (3,4) (3,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c6/fdtwnncn1vn0kw0f_jd84mcm0000gp/T/ipykernel_847/3078430593.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/c6/fdtwnncn1vn0kw0f_jd84mcm0000gp/T/ipykernel_847/992919234.py\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(self, output, y, learning_rate)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# output to h2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdc_dw_output_h2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcost_function_derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mnew_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdc_dw_output_h2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdc_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_function_derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3) (3,4) (3,3) "
     ]
    }
   ],
   "source": [
    "new_class.back_prop(outputs, np.reshape(list(pd.get_dummies(y_test).iloc[0]), [-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44758e6-2887-49bd-add2-9ee87982c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_class.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6700c6e-daaa-4cc4-81fc-304f208070b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_layer = [[0] for j in  range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ccb3f-b61c-46b3-9655-cb879ec099ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb7c04-8c8a-4998-826e-c18c498d39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape(current_layer, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700f9d0-6ac8-462c-8028-12ffc578e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.random.rand(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433e319-7056-45df-8ac0-f032713e9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1659d50-05ba-40c4-ace0-21772f68ccf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
