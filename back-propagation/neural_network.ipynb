{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dbb0df6-264e-4f31-8d4c-50dbb1cbbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap # for grgphing decision boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b89188-8ee5-45a7-b82e-1e8ffbcf16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "X_train = pd.read_csv(f'./{data_folder}/X_train.csv')\n",
    "y_train = pd.read_csv(f'./{data_folder}/y_train.csv')\n",
    "X_test = pd.read_csv(f'./{data_folder}/X_test.csv')\n",
    "y_test = pd.read_csv(f'./{data_folder}/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3f4671-84b2-44e5-ad53-b067585858a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        # layers/activations\n",
    "        self.input = np.random.rand(4, 1)\n",
    "        self.h1 = np.random.rand(2, 1)\n",
    "        self.h2 = np.random.rand(3, 1)\n",
    "        \n",
    "        # weights \n",
    "        self.w_1 = np.random.rand(2, 4)\n",
    "        self.w_2 = np.random.rand(3, 2)\n",
    "        \n",
    "        # biases \n",
    "        self.b_1 = np.random.rand(2, 1)\n",
    "        self.b_2 = np.random.rand(3, 1)\n",
    "\n",
    "        \n",
    "    def one_hot(self,y):\n",
    "        one_hot_y = np.zeros((y.size, y.max()+1))\n",
    "        one_hot_y[np.range(y,size), y] = 1\n",
    "        return one_hot_y.T\n",
    "\n",
    "    def relu(self,activations):\n",
    "        return np.maximum(0, activations)\n",
    "\n",
    "    def relu_deriv(self, activations):\n",
    "        return activations > 0\n",
    "\n",
    "    def softmax(self, activations):\n",
    "        return np.exp(activations) / np.sum(np.exp(activations))\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        # input\n",
    "        # reshapre the input into vector form.\n",
    "        # Example [1, 0, 0] -> [[1], [1], [1]]\n",
    "        self.input = np.reshape(X, (-1,1))\n",
    "        \n",
    "        # input -> h1\n",
    "        # the activations in the first hidden layer are given by the dot product \n",
    "        # of the weights by the input plus some biass its all then passed into\n",
    "        # our activation function. relu(W_1*x+b_1)\n",
    "        h1_activations = self.relu(np.dot(self.w_1, self.input) + self.b_1)\n",
    "        self.h1 = h1_activations\n",
    "\n",
    "        # h1 -> h2\n",
    "        # the activations in the seocnd hidden layer (h_2) are given by the dot product \n",
    "        # of the second weights (w_2) by the previous activations (h1) plus the bias(b_2).\n",
    "        # W_2*h1+b_2\n",
    "        h2_activations = (np.dot(self.w_2, h1_activations) + self.b_2)\n",
    "        self.h2 = h2_activations \n",
    "\n",
    "        # h2 -> output \n",
    "        # our output activtions/predictions are given by the second layer activations (h_2)\n",
    "        # put into the softmax function. \n",
    "        output = self.softmax(self.h2)\n",
    "        \n",
    "        return (output, max(output))\n",
    "    \n",
    "    def back_prop(self, output, y, learning_rate=0.01):\n",
    "        y = np.reshape(y, (-1,1))\n",
    "#         print(input_)\n",
    "        \n",
    "        # Derivative of the cost function.\n",
    "        # The cost function is C = (output - y)^2\n",
    "        # The derivative of that is 2 (output - y)\n",
    "        dc = (2 * (output - y))\n",
    "        \n",
    "        # Derivative of the cost function with respect to the weights (w_2).\n",
    "        # The because our output is given by: output = w_2*h_1+b_2. The deriative\n",
    "        # of the cost function with respect to w_2 is: dc * h1\n",
    "        dc_dw2 = -learning_rate * dc.dot(self.h1.T)\n",
    "        b_2 = -learning_rate * dc\n",
    "\n",
    "\n",
    "        # Derivative of the cost function with respect to the first weights (w_1)\n",
    "        # h1 is given by w_1*x+b_1\n",
    "        h1_error = self.w_2.T.dot(dc) * self.relu_deriv(self.h1)\n",
    "        dc_dw1 = -learning_rate * (h1_error.dot(self.input.T))\n",
    "        b_1 = -learning_rate * h1_error\n",
    "        \n",
    "        # update all the weights\n",
    "        self.w_1 +=  dc_dw1\n",
    "        self.w_2 +=  dc_dw2\n",
    "        \n",
    "        # update all the biases\n",
    "        self.b_1 += b_1\n",
    "        self.b_2 += b_2\n",
    "        return 0\n",
    "       \n",
    "    def get_accuracy(self, data):\n",
    "        total = 0\n",
    "        error = 0\n",
    "        mse = 0\n",
    "        for index, row in data.iterrows():\n",
    "            # select the label\n",
    "            y = row.tolist()[4:]\n",
    "            # select the x\n",
    "            X = row.tolist()[:4] \n",
    "            output, predicted = self.feed_forward(X)\n",
    "            label_index = y.index(max(y))\n",
    "            predicted_index = np.where(output==predicted)[0][0]\n",
    "            if label_index == predicted_index:\n",
    "                total += 1\n",
    "            error += (error, (np.reshape(y, (-1,1))**2))\n",
    "        return total/data.shape[0]\n",
    "        \n",
    "\n",
    "    def train(self, X, Y, itterations):        \n",
    "        y_dummies = pd.get_dummies(Y)\n",
    "        data = pd.concat([X, y_dummies], axis=1)\n",
    "        mse = 0\n",
    "        error = 0\n",
    "        for i in range(itterations):\n",
    "            iteration = i\n",
    "            total = 0\n",
    "            for index, row in data.iterrows():\n",
    "                # select the label\n",
    "                y = row.tolist()[4:]\n",
    "                # select the x\n",
    "                x = row.tolist()[:4] \n",
    "                # feed forward\n",
    "                output, predicted = self.feed_forward(x)\n",
    "                # back prop\n",
    "                self.back_prop(output, y)\n",
    "                # check if its a correct answer\n",
    "                label_index = y.index(max(y))\n",
    "                predicted_index = np.where(output==predicted)[0][0]\n",
    "                if label_index == predicted_index:\n",
    "                    total += 1\n",
    "                # add to the error\n",
    "                error += (error, (np.reshape(y, (-1,1))**2)) \n",
    "        training_accuracy = self.get_accuracy(data)\n",
    "        mse = error/data.shape[0]\n",
    "        return training_accuracy, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90eb6e7c-be61-4b80-8ea6-ef03f98a5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X_test, pd.get_dummies(y_test)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d98d4d-1212-4c11-ba66-b75480abcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30effb8b-e8ee-473a-85c3-5f40a69a73a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732142857142857"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.train(X_train, y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992bdbbb-1015-41c2-8d54-44b18ea6ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {nn.get_accuracy(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca859202-27d0-492f-80d3-86598ac6192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add confusion matrix to show how the network is classifying things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5b83a3d-1056-47a4-82e1-4737ea96bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(iterations, X_train, y_train, test_data):\n",
    "    \"\"\"\n",
    "    This function will return data to graph how our neural network\n",
    "    changes as we increas the iterations. \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns=['iteration', 'training_accuracy', 'tetst_accuracy'])\n",
    "    for i in iterations:\n",
    "        # create a new network\n",
    "        network = Network()\n",
    "        # train our network (also return trainin accuracy)\n",
    "        training_accuracy = network.train(X_train, y_train, i)\n",
    "        # returns test accuracy\n",
    "        test_accuracy = network.get_accuracy(test_data)\n",
    "        # add to df\n",
    "        df.loc[i] = [i] + [training_accuracy] + [test_accuracy]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb02a9-c874-4bf1-9013-2fbf58478205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff88eb9-f14c-4f5f-95dd-f6a3432cf5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [5, 10, 50, 100, 300, 600, 900, 1200, 1500, 1800, 2100, 2400, 2700, 3000, 3300]\n",
    "df = get_info(nums, X_train, y_train, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "216390cc-0d85-4ad4-b4b4-b5ff5bfdc7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>tetst_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>900.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>2100.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>2700.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>3300.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iteration  training_accuracy  tetst_accuracy\n",
       "5           5.0           0.732143        0.684211\n",
       "10         10.0           0.821429        0.789474\n",
       "50         50.0           0.946429        0.921053\n",
       "100       100.0           0.973214        0.921053\n",
       "300       300.0           0.973214        0.947368\n",
       "600       600.0           0.973214        0.947368\n",
       "900       900.0           0.973214        0.947368\n",
       "1200     1200.0           0.973214        0.947368\n",
       "1500     1500.0           0.973214        0.947368\n",
       "1800     1800.0           0.982143        0.947368\n",
       "2100     2100.0           0.973214        0.947368\n",
       "2400     2400.0           0.964286        0.947368\n",
       "2700     2700.0           0.964286        0.947368\n",
       "3000     3000.0           0.973214        1.000000\n",
       "3300     3300.0           0.964286        1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f111d9-7cfd-4998-8667-7412001273db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: graph this with the lost as iterations\n",
    "plt.scatter(df['iteration'], df['training_accuracy'])\n",
    "plt.scatter(df['iteration'], df['tetst_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f26740-0e4b-4d75-afbe-75d91c33dc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
