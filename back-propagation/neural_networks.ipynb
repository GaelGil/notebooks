{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274261cc-ff9f-4d9b-9f72-81ef0e65b5d7",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "In this notebook I will go over some of the basics of a fully connect feed forward neural network. I will mainly focus on their applications, how neural networks are formed, and the math. In this notebook I will be creating a neural network with only using `numpy` (a python library). This notebook will also use the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) as an example. Things that will be useful to understand going into this notebook are simple python, matrix multiplication and multivariable calculus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26541d35-ee3e-404c-8101-42409b2771bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e0d811-41c6-4de2-b752-98f50ab9484d",
   "metadata": {},
   "source": [
    "# The Data\n",
    "Neural networks are very powerful tools that can help us solve problems that are non linear. For example if we have some data that is linear seperable we can easily use any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84ef9278-e2e4-4b07-bce1-aac11da8e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "X_train = pd.read_csv(f'./{data_folder}/X_train.csv')\n",
    "y_train = pd.read_csv(f'./{data_folder}/y_train.csv')\n",
    "X_test = pd.read_csv(f'./{data_folder}/X_test.csv')\n",
    "y_test = pd.read_csv(f'./{data_folder}/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54daff26-8c49-4228-98d4-052d8fd10bdb",
   "metadata": {},
   "source": [
    "Taking a look at our data we can see that there are multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7382ffc7-d7cf-4b20-92f9-04b7452715eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.5               2.4                3.7               1.0\n",
       "1                  4.8               3.0                1.4               0.1\n",
       "2                  5.5               2.6                4.4               1.2\n",
       "3                  5.0               3.2                1.2               0.2\n",
       "4                  6.9               3.1                5.1               2.3\n",
       "..                 ...               ...                ...               ...\n",
       "107                6.3               2.7                4.9               1.8\n",
       "108                7.2               3.0                5.8               1.6\n",
       "109                5.8               4.0                1.2               0.2\n",
       "110                5.2               3.4                1.4               0.2\n",
       "111                7.2               3.2                6.0               1.8\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716d82a-6dfd-4f84-a542-72b169d77c84",
   "metadata": {},
   "source": [
    "To further drive the point that simple logistic regression will not work we will graph the data to see what it looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4758fc-b766-4394-8563-d605022ae258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: graph with color\n",
    "plt.scatter(X_train['sepal length (cm)'], X_train['sepal width (cm)'])\n",
    "plt.xlabel('sepal length cm')\n",
    "plt.ylabel('sepal width cm')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f5d89-6b8e-4e88-a91d-bf30d8079819",
   "metadata": {},
   "source": [
    "Now that we have taken a look at our data we can get into "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6254fd-8c7c-48cf-8d3d-302e3e0a5049",
   "metadata": {},
   "source": [
    "# Neural Network Anatomy\n",
    "A neural network is formed by an input layer, some number of hidden layers, and an ouput layer. All of these layers contain some number of neurons. The input layer has as many neurons as it does inputs. For example in our network our input layer will have four neurons for `sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)`. Simiarly our output layer has as many neurons as it does classes. For example we have the three classes `Iris-versicolor, Iris-setosa, Iris-virginica` so we will have three output neurons. As I mentioned we can have as many hidden layers as we want. Within the hidden layers we can have as many neurons as we choose as well. To demonstrate what a nerual network looks like below is an image of the neural network that is made later in this notebook.\n",
    "\n",
    "The lines connecting the input layer to the first hidden layers are called weights same for the first hidden layer to the second hidden layers. These weights are what we will later be adjusting using back propogation.\n",
    "\n",
    "The idea of the nueral network is that we have some inputs and we want to pass them forward to through the network (from the input to hidden layers and to the output). The"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3cad9-74c3-495f-ba16-e363c8bd3eb6",
   "metadata": {},
   "source": [
    "# The Math (Feeding Forward)\n",
    "To feed forward an input from the input layer to the first hidden layer we will multiply all inputs $\\vec{x}$ by all the weights connecting the input layer to h1 $W_1$ and add some bias $b_1$. Doing all that will give us $h_1$. We then apply some non linearity function to that and that will be our activations. In this case we are using relu. This looks like this: \n",
    "$$ \\vec{z_1} = relu(\\vec{h_1})$$\n",
    "$$ \\vec{h_1} = W_1 * \\vec{x} + \\vec{b_1} $$\n",
    "$$ \\vec{z_1} = relu(W_1 * \\vec{x} + \\vec{b_1})$$\n",
    "\n",
    "Now we just continue this unitl we get to the output layer. So to keep forwarding this input we would now do this: \n",
    "\n",
    "$$ \\vec{z_2} = relu(\\vec{h_2})$$\n",
    "$$ \\vec{h_2} = W_2 * \\vec{z_1} + \\vec{b_2} $$\n",
    "$$ \\vec{z_2} = relu(W_2 * \\vec{h_1} + \\vec{b_2})$$\n",
    "\n",
    "And lastly our ouput will simply just be:\n",
    "$$ \\hat{y} = softmax(\\vec{z_2}) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9b866-5c46-44a6-a4ec-e0eee916eed6",
   "metadata": {},
   "source": [
    "# Back Propogation\n",
    "As I mentioned there are weights and biases. We can manually adjust them or set them to random variables to see which values give us the best result. This of course is not a good proccess seeing how our network has so many weights and biases. What we want to do instead is learn the values we need to change our weights and biases to in order to minimise our loss. We can do this with calculus. We can do this by taking the negative gradient of our cost function ($ C = (\\hat{y}-y)^2$). Below I will explain the math that allows us to learn the values for our weights and biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009751c-da39-4b67-b374-e781e654b98d",
   "metadata": {},
   "source": [
    "This is a basic example of what our network looks like. We have an input($X$), two hidden layers ($h_1,h_2$) and two weights ($W_1,W_2$). \n",
    "$$ X ---W_1---> h_1 ---W_2---> h_2$$\n",
    "\n",
    "To calculate the error that our network produces we use the cost function $ C = (\\hat{y} - y)^2 $\n",
    "where $ \\hat{y} $ is the output vector/activations and $ y $ is the label as a vector. An example of what these look like is $ \\hat{y} = \\begin{bmatrix}\n",
    "0.8 \\\\\n",
    "0.1 \\\\\n",
    "0.1 \n",
    "\\end{bmatrix} $ and $ \\hat{y} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "As I mentioned our output is $\\hat{y}$ which is given by the follwing function $\\hat{y} = relu{(z^\\hat{y})}$. The activations $z^\\hat{y}$ are passed trough the relu function. $z^\\hat{y}$ is given by this\n",
    "\n",
    "$$ z^\\hat{y} = W_3 * \\vec{h_2} + \\vec{b_3}  $$\n",
    "\n",
    "In the euqation above we see that the output activations is given by the weights ($W_3$) multiplied by the previous layers activations ($\\vec{h_2}$) and lastly we add some bias ($\\vec{b_3}$). In network example at the top our weights, biases and activations are all scalers but in all these examples I will use the vector notation $\\vec{v}$\n",
    "\n",
    "Now that we have defined all of our functions we can see how they are all conected. We can take the gradient of our cost function $C$ using the chain rule. This will help us see how much the weights $W_3$ affect the cost function \n",
    "$$ \\frac{\\partial C}{\\partial W_3} = \\frac{\\partial C}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial z^\\hat{y}} \\frac{\\partial z^\\hat{y}}{\\partial W_3} = 2(\\hat{y} - y) * relu{(z^\\hat{y})} * \\vec{h_2} $$\n",
    "\n",
    "This will tell us by how much we should change the weights in $W_3$\n",
    "\n",
    "Now we will continue this proccess propagating the error backwards checking how the weights affect each layer/thecost. Next we change our previous $z^\\hat{y}$ function. It now looks like. $$ z^{h2} = W_2 * \\vec{h_1} + \\vec{b_2}  $$\n",
    " So now we will do $ \\frac{\\partial h_2}{\\partial W_2}$. This will look like this: $$ \\frac{\\partial h_2}{\\partial w_2} = \\frac{\\partial h_2}{\\partial z^{h_2}} \\frac{\\partial z^{h_2}}{\\partial W_2} \\frac{\\partial C}{\\partial W_3} = relu{(z^{h_2})} * h_1 * \\frac{\\partial C}{\\partial W_3} $$\n",
    " \n",
    " \n",
    "This will tell us by how much we should change the weights in $\\vec{w_2}$\n",
    "\n",
    "\n",
    "Now we will continue this proccess propagating the error backwards checking how the weights affect each layer. First I will update our previous $z^{h2}$ function. It now looks like. $$ z^{h_1} = W_1 * \\vec{X} + \\vec{b_1}  $$\n",
    " So next our we will do $ \\frac{\\partial h_1}{\\partial W_1}$. This will look like this: $$ \\frac{\\partial h_1}{\\partial W_1} = \\frac{\\partial h_1}{\\partial z^{h_1}} \\frac{\\partial z^{h_1}}{\\partial W_1} \\frac{\\partial C}{\\partial W_3} = relu{(z^{h_1})} * X * \\frac{\\partial h_2}{\\partial W_2} *\\frac{\\partial C}{\\partial W_3} $$\n",
    " \n",
    " \n",
    "Lastly we this will tell us by how much we should change the weights in $W_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465205f8-0be9-4c4e-b096-11d97e29aae9",
   "metadata": {},
   "source": [
    "Now that we have talked about how a neural network feeds forward an input to get and output. And that we have went over how we can learn the values of the weights and biases of our neural network, it is time to build one. Below is the code to a neural network class which we will train to classify dataset. The network below has an input layer of four nerons for our for inputs, 2 hidden layers one of two neurons and one of 3 output neurons. I will go over how a neural network is trained below as well but as mentioned it involves the calculus that is explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e80ed6-9b67-4a33-baff-322cc4200ab2",
   "metadata": {},
   "source": [
    "# Creating the Network\n",
    "Below is the code for a neural network. As explained earlier our network will have a input layer, two hidden layers, and two weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed078904-669e-48d0-a372-ae6da15c247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        # layers/activations\n",
    "        self.input = np.random.rand(4, 1)\n",
    "        self.h1 = np.random.rand(2, 1)\n",
    "        self.h2 = np.random.rand(3, 1)\n",
    "        \n",
    "        # weights \n",
    "        self.w_1 = np.random.rand(2, 4)\n",
    "        self.w_2 = np.random.rand(3, 2)\n",
    "        \n",
    "        # biases \n",
    "        self.b_1 = np.random.rand(2, 1)\n",
    "        self.b_2 = np.random.rand(3, 1)\n",
    "\n",
    "    def relu(self,activations):\n",
    "        return np.maximum(0, activations)\n",
    "\n",
    "    def relu_deriv(self, activations):\n",
    "        return activations > 0\n",
    "\n",
    "    def softmax(self, activations):\n",
    "        return np.exp(activations) / np.sum(np.exp(activations))\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        # input\n",
    "        # reshapre the input into vector form.\n",
    "        # Example [1, 0, 0] -> [[1], [1], [1]]\n",
    "        self.input = np.reshape(X, (-1,1))\n",
    "        \n",
    "        # input -> h1\n",
    "        # the activations in the first hidden layer are given by the dot product \n",
    "        # of the weights by the input plus some biass its all then passed into\n",
    "        # our activation function. relu(W_1*x+b_1)\n",
    "        h1_activations = self.relu(np.dot(self.w_1, self.input) + self.b_1)\n",
    "        self.h1 = h1_activations\n",
    "\n",
    "        # h1 -> h2\n",
    "        # the activations in the seocnd hidden layer (h_2) are given by the dot product \n",
    "        # of the second weights (w_2) by the previous activations (h1) plus the bias(b_2).\n",
    "        # W_2*h1+b_2\n",
    "        h2_activations = (np.dot(self.w_2, h1_activations) + self.b_2)\n",
    "        self.h2 = h2_activations \n",
    "\n",
    "        # h2 -> output \n",
    "        # our output activtions/predictions are given by the second layer activations (h_2)\n",
    "        # put into the softmax function. \n",
    "        output = self.softmax(self.h2)\n",
    "        \n",
    "        return (output, max(output))\n",
    "    \n",
    "    def back_prop(self, output, y, learning_rate=0.01):\n",
    "        y = np.reshape(y, (-1,1))\n",
    "        \n",
    "        # Derivative of the cost function.\n",
    "        # The cost function is C = (output - y)^2\n",
    "        # The derivative of that is 2 (output - y)\n",
    "        dc = (2 * (output - y))\n",
    "        \n",
    "        # Derivative of the cost function with respect to the weights (w_2).\n",
    "        # The because our output is given by: output = w_2*h_1+b_2. The deriative\n",
    "        # of the cost function with respect to w_2 is: dc * h1\n",
    "        dc_dw2 = -learning_rate * dc.dot(self.h1.T)\n",
    "        b_2 = -learning_rate * dc\n",
    "\n",
    "\n",
    "        # Derivative of the cost function with respect to the first weights (w_1)\n",
    "        # h1 is given by w_1*x+b_1\n",
    "        h1_error = self.w_2.T.dot(dc) * self.relu_deriv(self.h1)\n",
    "        dc_dw1 = -learning_rate * (h1_error.dot(self.input.T))\n",
    "        b_1 = -learning_rate * h1_error\n",
    "        \n",
    "        # update all the weights\n",
    "        self.w_1 +=  dc_dw1\n",
    "        self.w_2 +=  dc_dw2\n",
    "        \n",
    "        # update all the biases\n",
    "        self.b_1 += b_1\n",
    "        self.b_2 += b_2\n",
    "        return 0\n",
    "       \n",
    "    def get_accuracy(self, data):\n",
    "        total = 0\n",
    "        for index, row in data.iterrows():\n",
    "            # select the label\n",
    "            y = row.tolist()[4:]\n",
    "            # select the x\n",
    "            X = row.tolist()[:4] \n",
    "            output, predicted = self.feed_forward(X)\n",
    "            label_index = y.index(max(y))\n",
    "            predicted_index = np.where(output==predicted)[0][0]\n",
    "            if label_index == predicted_index:\n",
    "                total += 1\n",
    "        return total/data.shape[0]\n",
    "        \n",
    "\n",
    "    def train(self, X, Y, itterations):        \n",
    "        y_dummies = pd.get_dummies(Y)\n",
    "        data = pd.concat([X, y_dummies], axis=1)\n",
    "        for i in range(itterations):\n",
    "            for index, row in data.iterrows():\n",
    "                # select the label\n",
    "                y = row.tolist()[4:]\n",
    "                # select the x\n",
    "                x = row.tolist()[:4] \n",
    "                # feed forward\n",
    "                output, predicted = self.feed_forward(x)\n",
    "                # back prop\n",
    "                self.back_prop(output, y)\n",
    "        training_accuracy = self.get_accuracy(data)\n",
    "        return training_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39db34c-512b-4caa-aeed-2cebe509dc2d",
   "metadata": {},
   "source": [
    "# Using the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f173fd-4db3-4205-8ccb-f1ef5b07e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our test data into one dataframe \n",
    "data = pd.concat([X_test, pd.get_dummies(y_test)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d98d4d-1212-4c11-ba66-b75480abcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbc3e8c-79ed-4242-8d4d-8de4c7b0fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our network with 100 iterations\n",
    "training_accuracy = nn.train(X_train, y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a260a947-45c6-4d63-a721-7783cb7908fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9732142857142857\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy: {training_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992bdbbb-1015-41c2-8d54-44b18ea6ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {nn.get_accuracy(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d552b-eff8-4086-8b62-f2dd0e13a2c9",
   "metadata": {},
   "source": [
    "# Explaning Further Topics of Neural Networks \n",
    "- > dropput\n",
    "- > training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b83a3d-1056-47a4-82e1-4737ea96bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(iterations, X_train, y_train, test_data):\n",
    "    \"\"\"\n",
    "    This function will return data to graph how our neural network\n",
    "    changes as we increas the iterations. \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns=['iteration', 'training_accuracy', 'tetst_accuracy'])\n",
    "    for i in iterations:\n",
    "        # create a new network\n",
    "        network = Network()\n",
    "        # train our network (also return trainin accuracy)\n",
    "        training_accuracy = network.train(X_train, y_train, i)\n",
    "        # returns test accuracy\n",
    "        test_accuracy = network.get_accuracy(test_data)\n",
    "        # add to df\n",
    "        df.loc[i] = [i] + [training_accuracy] + [test_accuracy]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff88eb9-f14c-4f5f-95dd-f6a3432cf5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: This cell takes a long time to run\n",
    "nums = [1, 5, 10, 50, 100, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000]\n",
    "df = get_info(nums, X_train, y_train, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "216390cc-0d85-4ad4-b4b4-b5ff5bfdc7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>tetst_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iteration  training_accuracy  tetst_accuracy\n",
       "1           1.0           0.321429        0.368421\n",
       "5           5.0           0.732143        0.631579\n",
       "10         10.0           0.812500        0.789474\n",
       "50         50.0           0.946429        0.921053\n",
       "100       100.0           0.973214        0.921053\n",
       "500       500.0           0.973214        0.947368\n",
       "1000     1000.0           0.973214        0.947368\n",
       "1500     1500.0           0.973214        0.947368\n",
       "2000     2000.0           0.964286        1.000000\n",
       "2500     2500.0           0.964286        0.947368\n",
       "3000     3000.0           0.964286        1.000000\n",
       "3500     3500.0           0.973214        1.000000\n",
       "4000     4000.0           0.973214        1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09f111d9-7cfd-4998-8667-7412001273db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['iteration'], df['training_accuracy'], color='r', label='training accuracy')\n",
    "plt.scatter(df['iteration'], df['tetst_accuracy'], color='b', label='test accuracy')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6b1ef-9e75-4ae8-9f39-e0897a9a59b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3055ed1-11ee-4427-8302-4d217bea94a6",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4576778-e372-4fba-8ee6-6a715519f2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
