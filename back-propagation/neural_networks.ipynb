{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274261cc-ff9f-4d9b-9f72-81ef0e65b5d7",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "In this notebook I will go over some of the basics of a fully connect feed forward neural network. I will mainly focus on their applications, how neural networks are formed, and the math. In this notebook I will be creating a neural network with only using `numpy` (a python library). This notebook will also use the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) as an example. Things that will be useful to understand going into this notebook are simple python, matrix multiplication and multivariable calculus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26541d35-ee3e-404c-8101-42409b2771bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e0d811-41c6-4de2-b752-98f50ab9484d",
   "metadata": {},
   "source": [
    "# The Data\n",
    "Neural networks are very powerful tools that can help us solve problems with data that is non linear. For example if we have some data that is linear seperable we can easily draw a line to seperate and classify whatever it is we are trying to classify. But if we have some non linear data we can't do that. This is where neural networks come in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84ef9278-e2e4-4b07-bce1-aac11da8e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "X_train = pd.read_csv(f'./{data_folder}/X_train.csv')\n",
    "y_train = pd.read_csv(f'./{data_folder}/y_train.csv')\n",
    "X_test = pd.read_csv(f'./{data_folder}/X_test.csv')\n",
    "y_test = pd.read_csv(f'./{data_folder}/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54daff26-8c49-4228-98d4-052d8fd10bdb",
   "metadata": {},
   "source": [
    "Taking a look at our data we can see that there are multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7382ffc7-d7cf-4b20-92f9-04b7452715eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.5               2.4                3.7               1.0\n",
       "1                  4.8               3.0                1.4               0.1\n",
       "2                  5.5               2.6                4.4               1.2\n",
       "3                  5.0               3.2                1.2               0.2\n",
       "4                  6.9               3.1                5.1               2.3\n",
       "..                 ...               ...                ...               ...\n",
       "107                6.3               2.7                4.9               1.8\n",
       "108                7.2               3.0                5.8               1.6\n",
       "109                5.8               4.0                1.2               0.2\n",
       "110                5.2               3.4                1.4               0.2\n",
       "111                7.2               3.2                6.0               1.8\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716d82a-6dfd-4f84-a542-72b169d77c84",
   "metadata": {},
   "source": [
    "To further drive the point that simple logistic regression will not work we will graph the data to see what it looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4758fc-b766-4394-8563-d605022ae258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: graph with color\n",
    "plt.scatter(X_train['sepal length (cm)'], X_train['sepal width (cm)'])\n",
    "plt.xlabel('sepal length cm')\n",
    "plt.ylabel('sepal width cm')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f5d89-6b8e-4e88-a91d-bf30d8079819",
   "metadata": {},
   "source": [
    "Now that we have taken a look at our data we can get into "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6254fd-8c7c-48cf-8d3d-302e3e0a5049",
   "metadata": {},
   "source": [
    "# Neural Network Anatomy\n",
    "A neural network is formed by an input layer, some number of hidden layers, and an ouput layer. All of these layers contain some number of neurons. The input layer has as many neurons as it does inputs. For example in our network our input layer will have four neurons for `sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)`. Simiarly our output layer has as many neurons as it does classes. For example we have the three classes `Iris-versicolor, Iris-setosa, Iris-virginica` so we will have three output neurons. As I mentioned we can have as many hidden layers as we want. Within the hidden layers we can have as many neurons as we choose as well. To demonstrate what a nerual network looks like below is an image of the neural network that is made later in this notebook.\n",
    "\n",
    "The lines connecting the input layer to the first hidden layers are called weights same for the first hidden layer to the second hidden layers. These weights are what we will later be adjusting using back propogation.\n",
    "\n",
    "The idea of the nueral network is that we have some inputs and we want to pass them forward to through the network (from the input to hidden layers and to the output). The"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3cad9-74c3-495f-ba16-e363c8bd3eb6",
   "metadata": {},
   "source": [
    "# The Math (Feeding Forward)\n",
    "To feed forward an input from the input layer to the first hidden layer we will multiply all inputs $\\vec{x}$ by all the weights connecting the input layer to h1 $W_1$ and add some bias $b_1$. Doing all that will give us $h_1$. We then apply some non linearity function to that and that will be our activations. In this case we are using relu. This looks like this: \n",
    "$$ \\vec{z_1} = relu(\\vec{h_1})$$\n",
    "$$ \\vec{h_1} = W_1 * \\vec{x} + \\vec{b_1} $$\n",
    "$$ \\vec{z_1} = relu(W_1 * \\vec{x} + \\vec{b_1})$$\n",
    "\n",
    "Now we just continue this unitl we get to the output layer. So to keep forwarding this input we would now do this: \n",
    "\n",
    "$$ \\vec{z_2} = \\vec{h_2}$$\n",
    "$$ \\vec{h_2} = W_2 * \\vec{z_1} + \\vec{b_2} $$\n",
    "$$ \\vec{z_2} = W_2 * \\vec{z_1} + \\vec{b_2}$$\n",
    "\n",
    "And lastly our ouput will simply just be:\n",
    "$$ \\hat{y} = softmax(\\vec{z_2}) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9b866-5c46-44a6-a4ec-e0eee916eed6",
   "metadata": {},
   "source": [
    "# Back Propogation\n",
    "As I mentioned neural networks contain weights and biases. We can manually adjust them or set them to random variables to see which values give us the best result. This of course is not a good proccess seeing how our network has so many weights and biases. What we want to do instead is learn the values to our weights and biases that will minimise our loss. We can do this with calculus. We can do this by taking the negative gradient of our cost function ($ C = (\\hat{y}-y)^2$). The gradient gives the direction of fastest assent. So if we take the negative gradient we will approach a place in which our loss is as close to 0 as possible.  Below I will explain the math that allows us to learn the values for our weights and biases. This will involved mutlivariable calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009751c-da39-4b67-b374-e781e654b98d",
   "metadata": {},
   "source": [
    "This is a basic example of what our network looks like. We have an input($X$), two hidden layers ($h_1,h_2$) and two weights ($W_1,W_2$). \n",
    "$$ X ---W_1---> h_1 ---W_2---> h_2$$\n",
    "\n",
    "To calculate the error that our network produces we use the cost function $ C = (\\hat{y} - y)^2 $\n",
    "where $ \\hat{y} $ is the output vector/activations and $ y $ is the label as a vector. An example of what these look like is $ \\hat{y} = \\begin{bmatrix}\n",
    "0.8 \\\\\n",
    "0.1 \\\\\n",
    "0.1 \n",
    "\\end{bmatrix} $ and $ \\hat{y} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "As I mentioned our output is $\\hat{y}$ which is given by the follwing function $\\hat{y} = softmax(h_2)$. The activations $h_2$ are passed trough the softmax function. \n",
    "\n",
    "$$ \\hat{y} = softmax( W_2 * \\vec{h_1} + \\vec{b_2} ) $$\n",
    "\n",
    "As we saw above to feed forward and input we use a series of functions. For example to get the first hidden layers activations we do this $ \\vec{z_1} = relu(W_1 * \\vec{x} + \\vec{b_1})$. What we want to do now is see how much each weight and bias is affecting our cost. In other words whats the derivative of the cost function $C$ with respect to $W_1$. \n",
    "\n",
    "In the example below we will take the derivative of our cost function with respect to the second weights ($W_2$).\n",
    "$$ C = (\\hat{y}-y)^2  \\hspace{10mm} \\frac{\\partial C}  {\\partial \\hat{y}} = 2(\\hat{y} - y)$$\n",
    "\n",
    "$$ z^\\hat{y} = W_2 * \\vec{z_1} + \\vec{b_2}  \\hspace{10mm}  \\frac{\\partial z^\\hat{y}}{\\partial W_2} = \\vec{z_1}$$\n",
    "\n",
    "$$ \\frac{\\partial C}{\\partial W_2} = \\frac{\\partial C}{\\partial \\hat{y}} \\frac{\\partial z^\\hat{y}}{\\partial W_2} = 2(\\hat{y} - y) * \\vec{h_1} $$\n",
    "\n",
    "This will tell us by how much we should change the weights in $W_2$ Now we just continue this proccess until we reach the input layer. But first we need to calculate the error produced by the activations in the first hidden layer $\\frac{\\partial C}{\\partial h_1}$.\n",
    "\n",
    "$$ C = (\\hat{y}-y)^2  \\hspace{10mm} \\frac{\\partial C}  {\\partial \\hat{y}} = 2(\\hat{y} - y)$$\n",
    "$$ \\hat{y} = h_2  \\hspace{10mm} \\frac{\\partial \\hat{y}}  {\\partial h_2}$$\n",
    "$$ h_2 = W_2 *z_1 + b_1 \\hspace{10mm} \\frac{\\partial h_2}  {\\partial z_1} = W_2$$\n",
    "$$ z_1 = relu(h_1) \\hspace{10mm} \\frac{\\partial z_1}  {\\partial h_1} = relu`(h_1)$$\n",
    "\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial C}{\\partial h_1} = \\frac{\\partial C}  {\\partial \\hat{y}} \\frac{\\partial \\hat{y}}  {\\partial h_2} \\frac{\\partial h_2}  {\\partial z_1} \\frac{\\partial z_1}  {\\partial h_1} = 2(\\hat{y} - y) *  W_2 * relu`(h_1)$$\n",
    "\n",
    "$$ 2(\\hat{y} - y) *  W_2 * relu`(h_1) $$ This will tell us the error in the first hidden layer. Now we can continue our back propogation. Our next derivative to get is going to be $\\frac{\\partial h_1}{\\partial W_1}$. This will tell use how to change the weights in $W_1$. Because we have calculated all of our chain rule deriatives all that is left is just now.\n",
    "\n",
    "$$ h_1 = \\vec{x}*W_1+b_1 \\hspace{10mm} \\frac{\\partial h_1}  {\\partial W_1} = \\vec{x}$$\n",
    "\n",
    "$$ \\frac{\\partial C}  {\\partial h_1} \\frac{\\partial h_1}  {\\partial W_1}  = \\vec{x}\\frac{\\partial C}  {\\partial h_1} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465205f8-0be9-4c4e-b096-11d97e29aae9",
   "metadata": {},
   "source": [
    "Now that we have talked about how a neural network feeds forward an input to get and output. And that we have went over how we can learn the values of the weights and biases of our neural network, it is time to build one. Below is the code to a neural network class which we will train to classify dataset. The network below has an input layer of four nerons for our for inputs, 2 hidden layers one of two neurons and one of 3 output neurons. I will go over how a neural network is trained below as well but as mentioned it involves the calculus that is explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e80ed6-9b67-4a33-baff-322cc4200ab2",
   "metadata": {},
   "source": [
    "# Creating the Network\n",
    "Below is the code for a neural network. As explained earlier our network will have a input layer, two hidden layers, and two weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed078904-669e-48d0-a372-ae6da15c247e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (374311209.py, line 63)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/c6/fdtwnncn1vn0kw0f_jd84mcm0000gp/T/ipykernel_1771/374311209.py\"\u001b[0;36m, line \u001b[0;32m63\u001b[0m\n\u001b[0;31m    = -learning_rate * output_error.dot(self.h1.T)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        # layers/activations\n",
    "        self.input = np.random.rand(4, 1)\n",
    "        self.h1 = np.random.rand(2, 1)\n",
    "        self.h2 = np.random.rand(3, 1)\n",
    "        \n",
    "        # weights \n",
    "        self.w_1 = np.random.rand(2, 4)\n",
    "        self.w_2 = np.random.rand(3, 2)\n",
    "        \n",
    "        # biases \n",
    "        self.b_1 = np.random.rand(2, 1)\n",
    "        self.b_2 = np.random.rand(3, 1)\n",
    "\n",
    "    def relu(self,activations):\n",
    "        return np.maximum(0, activations)\n",
    "\n",
    "    def relu_deriv(self, activations):\n",
    "        return activations > 0\n",
    "\n",
    "    def softmax(self, activations):\n",
    "        return np.exp(activations) / np.sum(np.exp(activations))\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        # input\n",
    "        # reshapre the input into vector form.\n",
    "        # Example [1, 0, 0] -> [[1], [1], [1]]\n",
    "        self.input = np.reshape(X, (-1,1))\n",
    "        \n",
    "        # input -> h1\n",
    "        # the activations in the first hidden layer are given by the dot product \n",
    "        # of the weights by the input plus some biass its all then passed into\n",
    "        # our activation function. relu(W_1*x+b_1)\n",
    "        h1_activations = self.relu(np.dot(self.w_1, self.input) + self.b_1)\n",
    "        self.h1 = h1_activations\n",
    "\n",
    "        # h1 -> h2\n",
    "        # the activations in the seocnd hidden layer (h_2) are given by the dot product \n",
    "        # of the second weights (w_2) by the previous activations (h1) plus the bias(b_2).\n",
    "        # W_2*h1+b_2\n",
    "        h2_activations = (np.dot(self.w_2, h1_activations) + self.b_2)\n",
    "        self.h2 = h2_activations \n",
    "\n",
    "        # h2 -> output \n",
    "        # our output activtions/predictions are given by the second layer activations (h_2)\n",
    "        # put into the softmax function. \n",
    "        output = self.softmax(self.h2)\n",
    "        \n",
    "        return (output, max(output))\n",
    "    \n",
    "    def back_prop(self, output, y, learning_rate=0.01):\n",
    "        y = np.reshape(y, (-1,1))\n",
    "        \n",
    "        output_error = (2 * (output - y))\n",
    "        \n",
    "        dw_2 = -learning_rate * output_error.dot(self.h1.T)\n",
    "        b_2 = -learning_rate * output_error\n",
    "\n",
    "        h1_error = self.w_2.T.dot(output_error) * self.relu_deriv(h1)\n",
    "        dw_1 = -learning_rate * h1_error.dot(self.input.T)\n",
    "        b1 = -learning_rate * h1_error\n",
    "        \n",
    "        \n",
    "        # update all the weights\n",
    "        self.w_1 +=  dc_dw1\n",
    "        self.w_2 +=  dc_dw2\n",
    "        \n",
    "        # update all the biases\n",
    "        self.b_1 += b_1\n",
    "        self.b_2 += b_2\n",
    "        return 0\n",
    "       \n",
    "    def get_accuracy(self, data):\n",
    "        total = 0\n",
    "        for index, row in data.iterrows():\n",
    "            # select the label\n",
    "            y = row.tolist()[4:]\n",
    "            # select the x\n",
    "            X = row.tolist()[:4] \n",
    "            output, predicted = self.feed_forward(X)\n",
    "            label_index = y.index(max(y))\n",
    "            predicted_index = np.where(output==predicted)[0][0]\n",
    "            if label_index == predicted_index:\n",
    "                total += 1\n",
    "        return total/data.shape[0]\n",
    "        \n",
    "\n",
    "    def train(self, X, Y, itterations):        \n",
    "        y_dummies = pd.get_dummies(Y)\n",
    "        data = pd.concat([X, y_dummies], axis=1)\n",
    "        for i in range(itterations):\n",
    "            for index, row in data.iterrows():\n",
    "                # select the label\n",
    "                y = row.tolist()[4:]\n",
    "                # select the x\n",
    "                x = row.tolist()[:4] \n",
    "                # feed forward\n",
    "                output, predicted = self.feed_forward(x)\n",
    "                # back prop\n",
    "                self.back_prop(output, y)\n",
    "        training_accuracy = self.get_accuracy(data)\n",
    "        return training_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39db34c-512b-4caa-aeed-2cebe509dc2d",
   "metadata": {},
   "source": [
    "# Using the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f173fd-4db3-4205-8ccb-f1ef5b07e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our test data into one dataframe \n",
    "data = pd.concat([X_test, pd.get_dummies(y_test)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d98d4d-1212-4c11-ba66-b75480abcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbc3e8c-79ed-4242-8d4d-8de4c7b0fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our network with 100 iterations\n",
    "training_accuracy = nn.train(X_train, y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260a947-45c6-4d63-a721-7783cb7908fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9732142857142857\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy: {training_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bdbbb-1015-41c2-8d54-44b18ea6ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {nn.get_accuracy(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d552b-eff8-4086-8b62-f2dd0e13a2c9",
   "metadata": {},
   "source": [
    "# Explaning Further Topics of Neural Networks \n",
    "- > dropput\n",
    "- > training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b83a3d-1056-47a4-82e1-4737ea96bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(iterations, X_train, y_train, test_data):\n",
    "    \"\"\"\n",
    "    This function will return data to graph how our neural network\n",
    "    changes as we increas the iterations. \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns=['iteration', 'training_accuracy', 'tetst_accuracy'])\n",
    "    for i in iterations:\n",
    "        # create a new network\n",
    "        network = Network()\n",
    "        # train our network (also return trainin accuracy)\n",
    "        training_accuracy = network.train(X_train, y_train, i)\n",
    "        # returns test accuracy\n",
    "        test_accuracy = network.get_accuracy(test_data)\n",
    "        # add to df\n",
    "        df.loc[i] = [i] + [training_accuracy] + [test_accuracy]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff88eb9-f14c-4f5f-95dd-f6a3432cf5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: This cell takes a long time to run\n",
    "nums = [1, 5, 10, 50, 100, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000]\n",
    "df = get_info(nums, X_train, y_train, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216390cc-0d85-4ad4-b4b4-b5ff5bfdc7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>tetst_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iteration  training_accuracy  tetst_accuracy\n",
       "1           1.0           0.660714        0.631579\n",
       "5           5.0           0.705357        0.631579\n",
       "10         10.0           0.812500        0.763158\n",
       "50         50.0           0.946429        0.921053\n",
       "100       100.0           0.973214        0.921053\n",
       "500       500.0           0.973214        0.947368\n",
       "1000     1000.0           0.973214        0.947368\n",
       "1500     1500.0           0.973214        0.947368\n",
       "2000     2000.0           0.973214        0.947368\n",
       "2500     2500.0           0.973214        0.947368\n",
       "3000     3000.0           0.964286        1.000000\n",
       "3500     3500.0           0.973214        1.000000\n",
       "4000     4000.0           0.973214        1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f111d9-7cfd-4998-8667-7412001273db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['iteration'], df['training_accuracy'], color='r', label='training accuracy')\n",
    "plt.scatter(df['iteration'], df['tetst_accuracy'], color='b', label='test accuracy')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6b1ef-9e75-4ae8-9f39-e0897a9a59b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3055ed1-11ee-4427-8302-4d217bea94a6",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4576778-e372-4fba-8ee6-6a715519f2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
